{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6jXxqUa/qcrC8NPsy/2Wa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdon021/Comp261_A5/blob/master/Class_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRDi0yBKDM5I",
        "colab_type": "text"
      },
      "source": [
        "% Title\n",
        "% ----\n",
        "\\title{Nueral Network: Projects 3D normal-dsitrbuted data onto a unit-radius Sphere}\n",
        "%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqsKBN_cDmV7",
        "colab_type": "text"
      },
      "source": [
        "### Introduction\n",
        "Task: Create a (fully connected) neural network model that approximate the function for project input data x (normal-distributed) onto a unit-radius sphere space.\n",
        "\n",
        "$y = f(x; \\theta, w) = \\phi(x; \\theta)^T w$\n",
        "\n",
        "Structure of report\n",
        "1. create Dataset X and corresponding Y that projected on the unit sphere.\n",
        "2. Define a cost function\n",
        "3. Define a optimization procedure\n",
        "4. Define a model\n",
        "5. Train the Model\n",
        "6. Define parameters\n",
        "7. Model performance\n",
        "8. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-bkKamI1UeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from mpl_toolkits import mplot3d\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tro7iEX-ew8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = [0, 0, 0]\n",
        "cov = [[1, 0, 0],\n",
        "       [0, 1, 0],\n",
        "       [0, 0, 1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dV4KPTEUMdA",
        "colab_type": "text"
      },
      "source": [
        "$\\mu = [0, 0, 0]$\n",
        "\n",
        "$\\Sigma=\n",
        "\\begin{bmatrix} \n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0\\\\\n",
        "0 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "X is generated with mean =0 and variance =1 (standard deviation = 1), they are randomly cluster around co-cordinate of [0, 0, 0] in a 3-D space.\n",
        "$X_i$ is linearly independent to each other with $i = \\{1, 2, 3\\}$. \n",
        "\n",
        "Y = X normalized by its euclidean distance.\n",
        "\n",
        "$Y_{ij} = \\frac{X_{ij}}{\\sqrt{X_{1j}^2 + X_{2j}^2+X_{3j}^2}}$\n",
        "\n",
        "Denominator is the radius of the sphere."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b135hxdIfNxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unit_sphere(data):\n",
        "  return np.array([[coord / math.sqrt(sum(coords * coords for coords in line)) for coord in line] for line in data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTrKt37dfPnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "united = np.random.multivariate_normal(mean, cov, 4000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObgwOT9zfTjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x11, x22, x33 = united.T\n",
        "united_y = unit_sphere(united)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEqaNvahfVfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6fc5cd6a-4bd6-4cb1-baf3-b1db25fb0f54"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(x11, x22, x33, 'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fe170fbacf8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eajOQWVmZ2Il",
        "colab_type": "text"
      },
      "source": [
        "### Training, validation, test split\n",
        "- using the train_test_split() function provided in sklearn.\n",
        "- Call the function twice to acquire Training set, Validation set and test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PmRxaopfXGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(united, united_y, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4uQtuxLfcLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stLTEF21nI8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "57375907-2700-47e9-9bc8-b5cf7424af20"
      },
      "source": [
        "x11, x22, x33 = Y_test.T\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(x11, x22, x33, 'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fe16d2f4630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6FVQAflffQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow import keras\n",
        "import keras.backend as kb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kacclnf9fglJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape = (3,))\n",
        "x1 = layers.Dense(10, activation=\"relu\")(inputs)\n",
        "x2 = layers.Dense(10, activation='relu')(x1)\n",
        "outputs = layers.Dense(3, activation='linear')(x2)\n",
        "model = keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtnkaX6_cChQ",
        "colab_type": "text"
      },
      "source": [
        "### Define Nueral Network architecture\n",
        "\n",
        "This is a Three-layer feedforward neural network\n",
        "\n",
        "$f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$\n",
        "\n",
        "$f^{(1)}$ is the first hidden layer with 10 neurons and activation function = ReLU\n",
        "\n",
        "$F^{(1)}(x) = W^Tx$\n",
        "\n",
        "In our case $x=[x_1, x_2, x_3]$\n",
        "\n",
        "$h_i = max\\{0, x* \\begin{bmatrix}{w_1 \\\\ w_2 \\\\ w_3} \\end{bmatrix} + bias\\}$\n",
        "\n",
        "$h_i$ is the first neuron of the first hidden layer, $i= \\{1,2,..,10\\}$, in 1 row.\n",
        "We have 10 neurons (unit) in the first hidden layer, so we have to multiply 10 sets of weights\n",
        "\n",
        "$$\n",
        "max\\{0,\n",
        "\\begin{bmatrix}\n",
        "w_{0,1} & w_{0,2} & w_{0,3} \\\\\n",
        "w_{1,1} & w_{1,2} & w_{1,3} \\\\\n",
        "w_{2,1} & w_{2,2} & w_{2,3} \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "w_{9,1} & w_{9,2} & w_{9,3} \\\\\n",
        "\\end{bmatrix} *\\begin{bmatrix}{x_0^{(0)} \\\\ x_1^{(0)} \\\\ x_2^{(0)}} \\end{bmatrix} + \\begin{bmatrix}{b_0 \\\\ \\vdots \\\\ b_9} \\end{bmatrix}\\}\n",
        "$$\n",
        "\n",
        "Applying ReLU function to each specific component of the resulting vector inside.\n",
        "\n",
        "Now we have a vector of activations for the first hidden layer $h^{(1)}$.\n",
        "\n",
        "\n",
        "$f^{(2)}$ is the second hidden layer with 10 neurons, and ReLU activation functions.\n",
        "\n",
        "\n",
        "$$\n",
        "max\\{0,\n",
        "\\begin{bmatrix}\n",
        "w_{0,1} & \\cdots & w_{0,9} \\\\\n",
        "w_{1,1} & \\cdots & w_{1,9} \\\\\n",
        "w_{2,1} & \\cdots & w_{2,9} \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "w_{9,1} & \\cdots & w_{9,9} \\\\\n",
        "\\end{bmatrix} *\\begin{bmatrix}{h_0^{(1)} \\\\ h_1^{(1)} \\\\ \\vdots \\\\ h_9^{(1)}} \\end{bmatrix} + \\begin{bmatrix}{b_0 \\\\ \\vdots \\\\ b_9} \\end{bmatrix}\\}\n",
        "$$\n",
        "\n",
        "Applying ReLU function to each specific component of the resulting vector inside.\n",
        "\n",
        "Now we have a vector of activations for the second hidden layer $h^{(2)}$.\n",
        "\n",
        "\n",
        "$f^{(3)}$ is an output layer with 3 output units, and Linear activation\n",
        "\n",
        "$$\n",
        "c*\\{\n",
        "\\begin{bmatrix}\n",
        "w_{0,1} & \\cdots & w_{0,9} \\\\\n",
        "w_{1,1} & \\cdots & w_{1,9} \\\\\n",
        "w_{2,1} & \\cdots & w_{2,9} \\\\\n",
        "\\end{bmatrix} *\\begin{bmatrix}{h_0^{(2)} \\\\ h_1^{(2)} \\\\ \\vdots \\\\ h_9^{(2)}} \\end{bmatrix} + \\begin{bmatrix}{b_0 \\\\ b_1 \\\\ b_2} \\end{bmatrix}\\}\n",
        "$$\n",
        "\n",
        "Applying Linear function to each specific component of the resulting vector inside.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6XLrbgufomH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training dataset\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt-4C5xIfpRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tf.cast(X_train, tf.float32)\n",
        "Y_train = tf.cast(Y_train, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBaHU1stfuGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = tf.cast(X_val, tf.float32)\n",
        "Y_val = tf.cast(Y_val, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPD_YTIzfrU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tf.cast(X_test, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--05jxiSf12q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creates a dataset with a separate element fro each row of the input tensor\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(buffer_size= 3000).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).shuffle(1000).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cNuUWdXgG8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "epochs = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9M4pfzBg_Pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an loss function # not effective\n",
        "def Keras_loss_function(y_actual, y_predicted):\n",
        "  mse = kb.mean(kb.sum(kb.square(y_actual - y_predicted))) # (1/n*(sum(sqr(Y-Y_hat))))\n",
        "  return mse\n",
        "\n",
        "# first 100 epochs is useful"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdPR2mxckwEg",
        "colab_type": "text"
      },
      "source": [
        "### Design a cost function\n",
        "For MiniBatch size = N\n",
        "Y_actual and Y_predict is a 100 (rows) * 3(columns) matrix\n",
        "\n",
        "2 Options\n",
        "\n",
        "First Option - custom cost function\n",
        "\n",
        "$$\n",
        "\\frac{\\sum\\limits_{j=1}^{N} \\sum\\limits_{i=1}^3 (Y_{actual(j,i)} - Y_{predict(j,i)})^2}{N}\n",
        "$$\n",
        "\n",
        "This is more traditional, one loss score for each mini-batch trained\n",
        "\n",
        "Second Option - tf.keras.losses.MSE\n",
        "\n",
        "$$\n",
        "\\frac{\\sum\\limits_{i=1}^3 (Y_{actual(j,i)} - Y_{predict(j,i)})^2}{3}\n",
        "$$\n",
        "\n",
        "output is a vector of loss score associates with each row in the minibatch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abjyZ81hdAoc",
        "colab_type": "text"
      },
      "source": [
        "### Model preparation\n",
        "1. Generate 4,000 rows of X and corresponding Y\n",
        "2. using the train_test_split() function provided in sklearn.\n",
        "3. Call the function first time to have 20% of dataset as test set, then call the function second time on the remaining 80% to get the training set and validation set.\n",
        "4. call tf.data.Dataset.from_tensor_slices() to create an input pipeline for both training and validation set, then chain with Dataset.batch() to make the Dataset object iterable.\n",
        "5. Define optimization function = 'Adam' with learning rate 0.001\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLza4WY8fXA7",
        "colab_type": "text"
      },
      "source": [
        "## Modelling\n",
        "1. In 1 epoch\n",
        "1. Sample a mini-batch = 100 rows from X_train and Y_train. \n",
        "2. Calculate the $\\hat{Y}$ by complete one feedforward process with the Nueral Network architecture described above.\n",
        "\n",
        "$\\hat{Y} = a*\\{W_3*max\\{0, W_2*max\\{0, W_1*x +b_1\\}+b_2\\} + b_3\\}$\n",
        "3. $W_1$ and $ W_2$  $W_3$ are the 3 weight matrix.\n",
        "4. they all initialized with very small randome non-zero number.\n",
        "5. $b_1, b_2, b_3$ are bias vectors, initialized with 0.\n",
        "6. After calculated the $\\hat{Y}$, apply the loss function to the $\\hat{Y}$ and actual $Y$ to get the score of performance of the feedforward model. \n",
        "7. Then the model calculates the partial derivative for each weight in weight matrix and each bias in every bias vector.\n",
        "\n",
        "### Update the weight\n",
        "\n",
        "- With standard Stochastic gradient descent, each weight and bias is updated by\n",
        "  - $w \\leftarrow  w -$ learning rate * gradient of w with respect to the cost function.\n",
        "\n",
        "- THe gradient with respect to each weight in the cost function is calculated in backpropagation using the chain rule.\n",
        "\n",
        "1. $h_1 = W_1x +b_1$\n",
        "2. $z_1 = \\alpha (h_1)$. $\\alpha $ is the ReLU activation function\n",
        "3. $h_2 = W_2z_1 + b_2$\n",
        "4. $z_2 = \\alpha(h_2)$\n",
        "5. $h_3 = W_3z_2 + b_3$\n",
        "5. $z_3 = \\alpha(h_3)$\n",
        "6. $L = LL(z_3 -Y) $\n",
        "\n",
        "- To calculate the partial derivative of one of weight $w_i$ in $W_3$ with respect to the $L$, in other word, how sensitive the $L$ function is to the small change of the $w_i$.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W_3} = \\frac{\\partial L}{\\partial z_3} * \\frac{\\partial z_3}{\\partial h_3}*\\frac{\\partial h_3}{\\partial W_3}\n",
        "$$\n",
        "\n",
        "- If I trying to solve it\n",
        "- $ \\frac{\\partial L}{\\partial z_3} = 2(z_3 - Y)$, Z_3 and Y are both vector in this case.\n",
        "- $ \\frac{\\partial z_3}{\\partial h_3}$ this $\\alpha$ the linear function is just a constant, so its basically the derivative of $h_3$\n",
        "- $\\frac{\\partial h_3}{\\partial W_3}$ is basically the derivative of $z_2$, which is $\\alpha'(h_2)$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgeRRLJ2kNbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_mse = np.array([])\n",
        "valid_mse = np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UCU9yX8gL0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e2868c4-48e3-4858-9984-ef6897baacb9"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "    # open a GradientTape to record the operations run during the feed forward\n",
        "    # enables aoto-partial-Differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "      # run the feed foward process of the layers.\n",
        "      # the operations that the layers apply to its inpurts and going to bee recorded on the GradientTape\n",
        "      linear = model(x_batch_train, training = True)\n",
        "      # compute the loss value for this minibatch\n",
        "      mse = Keras_loss_function(y_batch_train, linear)\n",
        "      # mse = tf.keras.losses.MSE(y_batch_train, linear)\n",
        "      # mse = keras.losses.mean_squared_error(y_batch_train, linear) # mse gives 3 number\n",
        "    # print(mse)\n",
        "    # use the gradient tap to automatically retrieve the gradients of the \n",
        "    # trainable variables with respect to the loss\n",
        "    # print(model.trainable_weights)\n",
        "    grads = tape.gradient(mse, model.trainable_weights)\n",
        "    # print(grads)\n",
        "    # weight + bias for every layer\n",
        "    # run one step of gradient dscent by updating the value of the variables to minize the loss\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    # print(model.trainable_weights,'\\n')\n",
        "    # print log information every 10 batches.\n",
        "    if step % 10 == 0:\n",
        "      print(\n",
        "          \"Training loss (for one batch) at step %d: %.4f\"\n",
        "          %(step, float(mse))\n",
        "      )\n",
        "      print(\"seen so far: %s samples\" % ((step +1) * 100))\n",
        "\n",
        "\n",
        "  # Run a validation loop at the end of each epoch\n",
        "  for x_batch_val, y_batch_val in val_dataset:\n",
        "    val_linear = model(x_batch_val, training = False)\n",
        "    val_mse = Keras_loss_function(y_batch_val, val_linear)\n",
        "\n",
        "  # print MSE for validation set\n",
        "  print(\"validation MSE: %.4f\" % (float(val_mse)))\n",
        "  training_mse = np.append(training_mse, float(mse))\n",
        "  valid_mse = np.append(valid_mse, float(val_mse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 127.1304\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 113.3082\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 112.1583\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 50.2005\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 100.8509\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 93.6756\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 90.0708\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 44.5308\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 94.3834\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 82.2447\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 83.4398\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 38.8270\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 74.0084\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 69.9005\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 73.6887\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 36.5707\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 70.2666\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 65.7328\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 63.2744\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 31.0992\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 63.8579\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 56.2422\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 53.4151\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 30.1525\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 51.9599\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 47.5594\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 45.0563\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 24.1580\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 43.8367\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 42.4825\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 36.4450\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 17.7779\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 37.7345\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 38.3265\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 29.2130\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 14.7996\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 31.1488\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 28.6379\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 25.7024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 11.2618\n",
            "\n",
            "Start of epoch 10\n",
            "Training loss (for one batch) at step 0: 25.7915\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 21.7329\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 21.1784\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 11.7216\n",
            "\n",
            "Start of epoch 11\n",
            "Training loss (for one batch) at step 0: 19.6377\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 17.9609\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 17.8833\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 9.2019\n",
            "\n",
            "Start of epoch 12\n",
            "Training loss (for one batch) at step 0: 17.1215\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 14.5677\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 16.1310\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 8.2302\n",
            "\n",
            "Start of epoch 13\n",
            "Training loss (for one batch) at step 0: 14.2007\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 14.5865\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 12.3895\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 7.7320\n",
            "\n",
            "Start of epoch 14\n",
            "Training loss (for one batch) at step 0: 11.8348\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 14.0765\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 10.2565\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 8.1793\n",
            "\n",
            "Start of epoch 15\n",
            "Training loss (for one batch) at step 0: 13.4227\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 12.0507\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 10.0466\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 6.0635\n",
            "\n",
            "Start of epoch 16\n",
            "Training loss (for one batch) at step 0: 11.5824\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 11.1473\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 11.6463\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.7438\n",
            "\n",
            "Start of epoch 17\n",
            "Training loss (for one batch) at step 0: 10.1796\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 11.6192\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 9.2144\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.6652\n",
            "\n",
            "Start of epoch 18\n",
            "Training loss (for one batch) at step 0: 10.3070\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.1533\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 8.8052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.2885\n",
            "\n",
            "Start of epoch 19\n",
            "Training loss (for one batch) at step 0: 8.9704\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.6803\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.6218\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.6164\n",
            "\n",
            "Start of epoch 20\n",
            "Training loss (for one batch) at step 0: 9.7583\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.9911\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.7188\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.2428\n",
            "\n",
            "Start of epoch 21\n",
            "Training loss (for one batch) at step 0: 7.7419\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 9.3963\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 8.7380\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.1129\n",
            "\n",
            "Start of epoch 22\n",
            "Training loss (for one batch) at step 0: 9.3066\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.4290\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.8024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.0977\n",
            "\n",
            "Start of epoch 23\n",
            "Training loss (for one batch) at step 0: 8.1336\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.9466\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.7104\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.3820\n",
            "\n",
            "Start of epoch 24\n",
            "Training loss (for one batch) at step 0: 6.3681\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.4601\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 9.4888\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.1794\n",
            "\n",
            "Start of epoch 25\n",
            "Training loss (for one batch) at step 0: 6.9099\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.9593\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.9683\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.3531\n",
            "\n",
            "Start of epoch 26\n",
            "Training loss (for one batch) at step 0: 8.1066\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.4392\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 8.8490\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.0123\n",
            "\n",
            "Start of epoch 27\n",
            "Training loss (for one batch) at step 0: 5.9962\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 7.2527\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 8.5477\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.0264\n",
            "\n",
            "Start of epoch 28\n",
            "Training loss (for one batch) at step 0: 6.2785\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.1013\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.3984\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.9376\n",
            "\n",
            "Start of epoch 29\n",
            "Training loss (for one batch) at step 0: 6.5816\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.5433\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.5279\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.6489\n",
            "\n",
            "Start of epoch 30\n",
            "Training loss (for one batch) at step 0: 6.1778\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.8960\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.3380\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.5269\n",
            "\n",
            "Start of epoch 31\n",
            "Training loss (for one batch) at step 0: 6.8229\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.6312\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.9163\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.0676\n",
            "\n",
            "Start of epoch 32\n",
            "Training loss (for one batch) at step 0: 6.3838\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.2705\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.6175\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.2445\n",
            "\n",
            "Start of epoch 33\n",
            "Training loss (for one batch) at step 0: 4.4246\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.3315\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.3760\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.9807\n",
            "\n",
            "Start of epoch 34\n",
            "Training loss (for one batch) at step 0: 6.2730\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.1752\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.3406\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.9788\n",
            "\n",
            "Start of epoch 35\n",
            "Training loss (for one batch) at step 0: 4.3001\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.5282\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.6576\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.6285\n",
            "\n",
            "Start of epoch 36\n",
            "Training loss (for one batch) at step 0: 4.3365\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.1784\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.5173\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8759\n",
            "\n",
            "Start of epoch 37\n",
            "Training loss (for one batch) at step 0: 5.2949\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.0890\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.0472\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.2702\n",
            "\n",
            "Start of epoch 38\n",
            "Training loss (for one batch) at step 0: 4.0545\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.7718\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.1006\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.2342\n",
            "\n",
            "Start of epoch 39\n",
            "Training loss (for one batch) at step 0: 4.0286\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.1169\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.3253\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.1107\n",
            "\n",
            "Start of epoch 40\n",
            "Training loss (for one batch) at step 0: 4.2602\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.6204\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.4302\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9228\n",
            "\n",
            "Start of epoch 41\n",
            "Training loss (for one batch) at step 0: 4.7081\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.1611\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.0662\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.1642\n",
            "\n",
            "Start of epoch 42\n",
            "Training loss (for one batch) at step 0: 4.0326\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.6793\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.4288\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.7030\n",
            "\n",
            "Start of epoch 43\n",
            "Training loss (for one batch) at step 0: 3.5504\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.1156\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.8804\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9926\n",
            "\n",
            "Start of epoch 44\n",
            "Training loss (for one batch) at step 0: 3.4297\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.3515\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.2920\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8429\n",
            "\n",
            "Start of epoch 45\n",
            "Training loss (for one batch) at step 0: 3.4051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.9653\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.4493\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9155\n",
            "\n",
            "Start of epoch 46\n",
            "Training loss (for one batch) at step 0: 3.7654\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8338\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.1330\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.2050\n",
            "\n",
            "Start of epoch 47\n",
            "Training loss (for one batch) at step 0: 5.1539\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4243\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.1558\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2783\n",
            "\n",
            "Start of epoch 48\n",
            "Training loss (for one batch) at step 0: 3.1987\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.7716\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.8834\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5805\n",
            "\n",
            "Start of epoch 49\n",
            "Training loss (for one batch) at step 0: 3.0719\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.0947\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.3349\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3655\n",
            "\n",
            "Start of epoch 50\n",
            "Training loss (for one batch) at step 0: 5.2351\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.9278\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4788\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8392\n",
            "\n",
            "Start of epoch 51\n",
            "Training loss (for one batch) at step 0: 3.7398\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4888\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.1226\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9877\n",
            "\n",
            "Start of epoch 52\n",
            "Training loss (for one batch) at step 0: 2.6567\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4519\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.3837\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.7707\n",
            "\n",
            "Start of epoch 53\n",
            "Training loss (for one batch) at step 0: 3.5968\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.0450\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.6134\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6547\n",
            "\n",
            "Start of epoch 54\n",
            "Training loss (for one batch) at step 0: 3.0739\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.5319\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1523\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3409\n",
            "\n",
            "Start of epoch 55\n",
            "Training loss (for one batch) at step 0: 3.6172\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4153\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.2980\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6120\n",
            "\n",
            "Start of epoch 56\n",
            "Training loss (for one batch) at step 0: 3.9579\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9692\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.5447\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1601\n",
            "\n",
            "Start of epoch 57\n",
            "Training loss (for one batch) at step 0: 2.3289\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.2650\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.3786\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2452\n",
            "\n",
            "Start of epoch 58\n",
            "Training loss (for one batch) at step 0: 3.8764\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1324\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7728\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3634\n",
            "\n",
            "Start of epoch 59\n",
            "Training loss (for one batch) at step 0: 2.6714\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9567\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.5229\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3965\n",
            "\n",
            "Start of epoch 60\n",
            "Training loss (for one batch) at step 0: 2.7123\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.7409\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0404\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5292\n",
            "\n",
            "Start of epoch 61\n",
            "Training loss (for one batch) at step 0: 2.5224\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4822\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6297\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2997\n",
            "\n",
            "Start of epoch 62\n",
            "Training loss (for one batch) at step 0: 3.8585\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.7394\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9669\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2688\n",
            "\n",
            "Start of epoch 63\n",
            "Training loss (for one batch) at step 0: 3.1058\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1383\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1620\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2096\n",
            "\n",
            "Start of epoch 64\n",
            "Training loss (for one batch) at step 0: 2.4827\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3923\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.8576\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9844\n",
            "\n",
            "Start of epoch 65\n",
            "Training loss (for one batch) at step 0: 2.5492\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.0075\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7389\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4072\n",
            "\n",
            "Start of epoch 66\n",
            "Training loss (for one batch) at step 0: 3.2083\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7824\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7854\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9684\n",
            "\n",
            "Start of epoch 67\n",
            "Training loss (for one batch) at step 0: 3.0489\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0468\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7586\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3255\n",
            "\n",
            "Start of epoch 68\n",
            "Training loss (for one batch) at step 0: 3.5161\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7429\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7091\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1067\n",
            "\n",
            "Start of epoch 69\n",
            "Training loss (for one batch) at step 0: 2.8910\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7695\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3290\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2733\n",
            "\n",
            "Start of epoch 70\n",
            "Training loss (for one batch) at step 0: 2.8200\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9019\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4485\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1441\n",
            "\n",
            "Start of epoch 71\n",
            "Training loss (for one batch) at step 0: 2.3733\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.0230\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4743\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2309\n",
            "\n",
            "Start of epoch 72\n",
            "Training loss (for one batch) at step 0: 2.8082\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9087\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7280\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4937\n",
            "\n",
            "Start of epoch 73\n",
            "Training loss (for one batch) at step 0: 2.5775\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4273\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5842\n",
            "\n",
            "Start of epoch 74\n",
            "Training loss (for one batch) at step 0: 2.2079\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5070\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9472\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0939\n",
            "\n",
            "Start of epoch 75\n",
            "Training loss (for one batch) at step 0: 2.1566\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7080\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3321\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0252\n",
            "\n",
            "Start of epoch 76\n",
            "Training loss (for one batch) at step 0: 2.7453\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6065\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2767\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2944\n",
            "\n",
            "Start of epoch 77\n",
            "Training loss (for one batch) at step 0: 3.1828\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4275\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4225\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7745\n",
            "\n",
            "Start of epoch 78\n",
            "Training loss (for one batch) at step 0: 1.7207\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5583\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.2078\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8214\n",
            "\n",
            "Start of epoch 79\n",
            "Training loss (for one batch) at step 0: 1.7941\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2400\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3712\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1000\n",
            "\n",
            "Start of epoch 80\n",
            "Training loss (for one batch) at step 0: 2.1949\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2163\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8173\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1227\n",
            "\n",
            "Start of epoch 81\n",
            "Training loss (for one batch) at step 0: 2.0825\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1763\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.5015\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0649\n",
            "\n",
            "Start of epoch 82\n",
            "Training loss (for one batch) at step 0: 1.7861\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2574\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2747\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1166\n",
            "\n",
            "Start of epoch 83\n",
            "Training loss (for one batch) at step 0: 1.9061\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8822\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.5898\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8547\n",
            "\n",
            "Start of epoch 84\n",
            "Training loss (for one batch) at step 0: 3.6633\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2856\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9699\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7549\n",
            "\n",
            "Start of epoch 85\n",
            "Training loss (for one batch) at step 0: 1.6014\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0953\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1981\n",
            "\n",
            "Start of epoch 86\n",
            "Training loss (for one batch) at step 0: 1.9437\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4786\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3214\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9110\n",
            "\n",
            "Start of epoch 87\n",
            "Training loss (for one batch) at step 0: 1.6194\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4464\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.0371\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7713\n",
            "\n",
            "Start of epoch 88\n",
            "Training loss (for one batch) at step 0: 1.8417\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7797\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6829\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8142\n",
            "\n",
            "Start of epoch 89\n",
            "Training loss (for one batch) at step 0: 2.1283\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.2575\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.0993\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0579\n",
            "\n",
            "Start of epoch 90\n",
            "Training loss (for one batch) at step 0: 3.3409\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5443\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3566\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6138\n",
            "\n",
            "Start of epoch 91\n",
            "Training loss (for one batch) at step 0: 2.2519\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5414\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2758\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3098\n",
            "\n",
            "Start of epoch 92\n",
            "Training loss (for one batch) at step 0: 2.7258\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7181\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0997\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7342\n",
            "\n",
            "Start of epoch 93\n",
            "Training loss (for one batch) at step 0: 2.2189\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0836\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9730\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0696\n",
            "\n",
            "Start of epoch 94\n",
            "Training loss (for one batch) at step 0: 1.8917\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0888\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4102\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5990\n",
            "\n",
            "Start of epoch 95\n",
            "Training loss (for one batch) at step 0: 1.9872\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8788\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4564\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7682\n",
            "\n",
            "Start of epoch 96\n",
            "Training loss (for one batch) at step 0: 2.2501\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0177\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7326\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6232\n",
            "\n",
            "Start of epoch 97\n",
            "Training loss (for one batch) at step 0: 1.7554\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6150\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.5249\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6154\n",
            "\n",
            "Start of epoch 98\n",
            "Training loss (for one batch) at step 0: 2.0221\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6538\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1823\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9245\n",
            "\n",
            "Start of epoch 99\n",
            "Training loss (for one batch) at step 0: 3.2419\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3739\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7641\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9811\n",
            "\n",
            "Start of epoch 100\n",
            "Training loss (for one batch) at step 0: 2.3155\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7174\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0184\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2447\n",
            "\n",
            "Start of epoch 101\n",
            "Training loss (for one batch) at step 0: 2.6171\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0956\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.5869\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3127\n",
            "\n",
            "Start of epoch 102\n",
            "Training loss (for one batch) at step 0: 2.0290\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4656\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3370\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6762\n",
            "\n",
            "Start of epoch 103\n",
            "Training loss (for one batch) at step 0: 1.9503\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6524\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6607\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9854\n",
            "\n",
            "Start of epoch 104\n",
            "Training loss (for one batch) at step 0: 2.6901\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0943\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8602\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0501\n",
            "\n",
            "Start of epoch 105\n",
            "Training loss (for one batch) at step 0: 1.7578\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5154\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4868\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7332\n",
            "\n",
            "Start of epoch 106\n",
            "Training loss (for one batch) at step 0: 2.6993\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1169\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8486\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8362\n",
            "\n",
            "Start of epoch 107\n",
            "Training loss (for one batch) at step 0: 1.9432\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2496\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9975\n",
            "\n",
            "Start of epoch 108\n",
            "Training loss (for one batch) at step 0: 1.5226\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0157\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7532\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6837\n",
            "\n",
            "Start of epoch 109\n",
            "Training loss (for one batch) at step 0: 1.6224\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9184\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4468\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6047\n",
            "\n",
            "Start of epoch 110\n",
            "Training loss (for one batch) at step 0: 1.9356\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6147\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9185\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7171\n",
            "\n",
            "Start of epoch 111\n",
            "Training loss (for one batch) at step 0: 2.4126\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6755\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3951\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4780\n",
            "\n",
            "Start of epoch 112\n",
            "Training loss (for one batch) at step 0: 1.5046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8331\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1178\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7970\n",
            "\n",
            "Start of epoch 113\n",
            "Training loss (for one batch) at step 0: 1.1650\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0210\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5729\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6541\n",
            "\n",
            "Start of epoch 114\n",
            "Training loss (for one batch) at step 0: 2.4576\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8748\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7209\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6172\n",
            "\n",
            "Start of epoch 115\n",
            "Training loss (for one batch) at step 0: 2.8757\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7789\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7100\n",
            "\n",
            "Start of epoch 116\n",
            "Training loss (for one batch) at step 0: 2.2781\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9424\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9352\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1263\n",
            "\n",
            "Start of epoch 117\n",
            "Training loss (for one batch) at step 0: 2.4444\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2270\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6956\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7461\n",
            "\n",
            "Start of epoch 118\n",
            "Training loss (for one batch) at step 0: 1.7111\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4319\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5599\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1322\n",
            "\n",
            "Start of epoch 119\n",
            "Training loss (for one batch) at step 0: 1.2610\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5428\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.6041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9271\n",
            "\n",
            "Start of epoch 120\n",
            "Training loss (for one batch) at step 0: 1.5811\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2224\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2860\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0659\n",
            "\n",
            "Start of epoch 121\n",
            "Training loss (for one batch) at step 0: 1.7706\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5208\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9586\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6671\n",
            "\n",
            "Start of epoch 122\n",
            "Training loss (for one batch) at step 0: 1.3743\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1442\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8779\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9667\n",
            "\n",
            "Start of epoch 123\n",
            "Training loss (for one batch) at step 0: 1.3039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6226\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3794\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9118\n",
            "\n",
            "Start of epoch 124\n",
            "Training loss (for one batch) at step 0: 1.8642\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8353\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4382\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1264\n",
            "\n",
            "Start of epoch 125\n",
            "Training loss (for one batch) at step 0: 1.6867\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2557\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7842\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5752\n",
            "\n",
            "Start of epoch 126\n",
            "Training loss (for one batch) at step 0: 1.1472\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7065\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6439\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8175\n",
            "\n",
            "Start of epoch 127\n",
            "Training loss (for one batch) at step 0: 1.2952\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3838\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0738\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1135\n",
            "\n",
            "Start of epoch 128\n",
            "Training loss (for one batch) at step 0: 1.9552\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8462\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.5669\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7908\n",
            "\n",
            "Start of epoch 129\n",
            "Training loss (for one batch) at step 0: 2.3883\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1318\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1874\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6291\n",
            "\n",
            "Start of epoch 130\n",
            "Training loss (for one batch) at step 0: 1.8773\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6515\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8786\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0269\n",
            "\n",
            "Start of epoch 131\n",
            "Training loss (for one batch) at step 0: 1.6519\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3690\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7811\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0714\n",
            "\n",
            "Start of epoch 132\n",
            "Training loss (for one batch) at step 0: 1.8587\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3313\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5497\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5813\n",
            "\n",
            "Start of epoch 133\n",
            "Training loss (for one batch) at step 0: 1.5740\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1937\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2571\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1933\n",
            "\n",
            "Start of epoch 134\n",
            "Training loss (for one batch) at step 0: 2.1510\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6270\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7449\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8755\n",
            "\n",
            "Start of epoch 135\n",
            "Training loss (for one batch) at step 0: 1.7271\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1454\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4976\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4670\n",
            "\n",
            "Start of epoch 136\n",
            "Training loss (for one batch) at step 0: 1.4810\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4377\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3409\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7771\n",
            "\n",
            "Start of epoch 137\n",
            "Training loss (for one batch) at step 0: 1.7746\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1537\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3227\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0509\n",
            "\n",
            "Start of epoch 138\n",
            "Training loss (for one batch) at step 0: 1.4010\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5023\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3787\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6267\n",
            "\n",
            "Start of epoch 139\n",
            "Training loss (for one batch) at step 0: 1.9020\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3278\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3692\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8361\n",
            "\n",
            "Start of epoch 140\n",
            "Training loss (for one batch) at step 0: 1.5323\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4320\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9588\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6901\n",
            "\n",
            "Start of epoch 141\n",
            "Training loss (for one batch) at step 0: 2.1615\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6091\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2229\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1067\n",
            "\n",
            "Start of epoch 142\n",
            "Training loss (for one batch) at step 0: 2.8064\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7244\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6558\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5786\n",
            "\n",
            "Start of epoch 143\n",
            "Training loss (for one batch) at step 0: 1.6677\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7917\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0149\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6401\n",
            "\n",
            "Start of epoch 144\n",
            "Training loss (for one batch) at step 0: 1.9786\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3116\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6162\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6891\n",
            "\n",
            "Start of epoch 145\n",
            "Training loss (for one batch) at step 0: 1.3600\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6942\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2214\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6837\n",
            "\n",
            "Start of epoch 146\n",
            "Training loss (for one batch) at step 0: 1.8257\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8649\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1959\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6028\n",
            "\n",
            "Start of epoch 147\n",
            "Training loss (for one batch) at step 0: 1.8894\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4635\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9008\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8410\n",
            "\n",
            "Start of epoch 148\n",
            "Training loss (for one batch) at step 0: 1.4203\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8764\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3181\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7628\n",
            "\n",
            "Start of epoch 149\n",
            "Training loss (for one batch) at step 0: 1.0276\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8814\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2873\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7996\n",
            "\n",
            "Start of epoch 150\n",
            "Training loss (for one batch) at step 0: 1.9536\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0229\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7376\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6848\n",
            "\n",
            "Start of epoch 151\n",
            "Training loss (for one batch) at step 0: 1.0659\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5659\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4291\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6144\n",
            "\n",
            "Start of epoch 152\n",
            "Training loss (for one batch) at step 0: 1.5279\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5653\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6494\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6452\n",
            "\n",
            "Start of epoch 153\n",
            "Training loss (for one batch) at step 0: 1.8858\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0302\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1930\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6740\n",
            "\n",
            "Start of epoch 154\n",
            "Training loss (for one batch) at step 0: 2.0507\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2646\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6720\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6925\n",
            "\n",
            "Start of epoch 155\n",
            "Training loss (for one batch) at step 0: 1.2811\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1711\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7662\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8417\n",
            "\n",
            "Start of epoch 156\n",
            "Training loss (for one batch) at step 0: 1.6554\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8142\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5623\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6834\n",
            "\n",
            "Start of epoch 157\n",
            "Training loss (for one batch) at step 0: 1.7091\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7408\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4339\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9351\n",
            "\n",
            "Start of epoch 158\n",
            "Training loss (for one batch) at step 0: 1.1828\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2699\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1154\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5373\n",
            "\n",
            "Start of epoch 159\n",
            "Training loss (for one batch) at step 0: 1.3745\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4010\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7098\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0941\n",
            "\n",
            "Start of epoch 160\n",
            "Training loss (for one batch) at step 0: 1.1227\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7239\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8327\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5238\n",
            "\n",
            "Start of epoch 161\n",
            "Training loss (for one batch) at step 0: 1.6598\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9802\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7120\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5252\n",
            "\n",
            "Start of epoch 162\n",
            "Training loss (for one batch) at step 0: 1.9065\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4019\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1514\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0145\n",
            "\n",
            "Start of epoch 163\n",
            "Training loss (for one batch) at step 0: 1.4064\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8440\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7053\n",
            "\n",
            "Start of epoch 164\n",
            "Training loss (for one batch) at step 0: 1.1657\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3772\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6766\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0339\n",
            "\n",
            "Start of epoch 165\n",
            "Training loss (for one batch) at step 0: 2.1273\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1917\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3733\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6553\n",
            "\n",
            "Start of epoch 166\n",
            "Training loss (for one batch) at step 0: 1.1005\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5970\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.1268\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5826\n",
            "\n",
            "Start of epoch 167\n",
            "Training loss (for one batch) at step 0: 1.4410\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8211\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1049\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5506\n",
            "\n",
            "Start of epoch 168\n",
            "Training loss (for one batch) at step 0: 1.5562\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5420\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7905\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8588\n",
            "\n",
            "Start of epoch 169\n",
            "Training loss (for one batch) at step 0: 1.5602\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1921\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5181\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5057\n",
            "\n",
            "Start of epoch 170\n",
            "Training loss (for one batch) at step 0: 1.7602\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4658\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0944\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6877\n",
            "\n",
            "Start of epoch 171\n",
            "Training loss (for one batch) at step 0: 1.5267\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9496\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4592\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5979\n",
            "\n",
            "Start of epoch 172\n",
            "Training loss (for one batch) at step 0: 1.1027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7648\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9076\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5748\n",
            "\n",
            "Start of epoch 173\n",
            "Training loss (for one batch) at step 0: 1.9594\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7500\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2091\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6323\n",
            "\n",
            "Start of epoch 174\n",
            "Training loss (for one batch) at step 0: 1.5590\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4556\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4390\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4812\n",
            "\n",
            "Start of epoch 175\n",
            "Training loss (for one batch) at step 0: 1.6153\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7966\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6250\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7667\n",
            "\n",
            "Start of epoch 176\n",
            "Training loss (for one batch) at step 0: 1.3146\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4012\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4141\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7499\n",
            "\n",
            "Start of epoch 177\n",
            "Training loss (for one batch) at step 0: 1.5150\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5444\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2948\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5642\n",
            "\n",
            "Start of epoch 178\n",
            "Training loss (for one batch) at step 0: 1.5120\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1291\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3188\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8080\n",
            "\n",
            "Start of epoch 179\n",
            "Training loss (for one batch) at step 0: 1.0941\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3156\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4686\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1835\n",
            "\n",
            "Start of epoch 180\n",
            "Training loss (for one batch) at step 0: 1.4217\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9565\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6489\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8385\n",
            "\n",
            "Start of epoch 181\n",
            "Training loss (for one batch) at step 0: 1.5838\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2505\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3557\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7607\n",
            "\n",
            "Start of epoch 182\n",
            "Training loss (for one batch) at step 0: 1.4454\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8584\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8595\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6922\n",
            "\n",
            "Start of epoch 183\n",
            "Training loss (for one batch) at step 0: 1.5461\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3179\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7964\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6373\n",
            "\n",
            "Start of epoch 184\n",
            "Training loss (for one batch) at step 0: 2.3365\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6952\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2792\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6146\n",
            "\n",
            "Start of epoch 185\n",
            "Training loss (for one batch) at step 0: 1.4634\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2336\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4399\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8594\n",
            "\n",
            "Start of epoch 186\n",
            "Training loss (for one batch) at step 0: 1.0641\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6645\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7134\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6774\n",
            "\n",
            "Start of epoch 187\n",
            "Training loss (for one batch) at step 0: 1.2944\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5958\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2206\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8792\n",
            "\n",
            "Start of epoch 188\n",
            "Training loss (for one batch) at step 0: 1.7668\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4136\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2703\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6307\n",
            "\n",
            "Start of epoch 189\n",
            "Training loss (for one batch) at step 0: 1.8363\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9590\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0368\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8352\n",
            "\n",
            "Start of epoch 190\n",
            "Training loss (for one batch) at step 0: 1.5728\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2078\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6393\n",
            "\n",
            "Start of epoch 191\n",
            "Training loss (for one batch) at step 0: 1.6458\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6534\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7893\n",
            "\n",
            "Start of epoch 192\n",
            "Training loss (for one batch) at step 0: 1.3123\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7786\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3156\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4863\n",
            "\n",
            "Start of epoch 193\n",
            "Training loss (for one batch) at step 0: 1.3132\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0172\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4311\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6177\n",
            "\n",
            "Start of epoch 194\n",
            "Training loss (for one batch) at step 0: 1.8289\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3476\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0714\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6528\n",
            "\n",
            "Start of epoch 195\n",
            "Training loss (for one batch) at step 0: 1.5466\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0100\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4486\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4475\n",
            "\n",
            "Start of epoch 196\n",
            "Training loss (for one batch) at step 0: 1.4653\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6163\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1353\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4864\n",
            "\n",
            "Start of epoch 197\n",
            "Training loss (for one batch) at step 0: 1.0676\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3888\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0611\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4569\n",
            "\n",
            "Start of epoch 198\n",
            "Training loss (for one batch) at step 0: 1.1322\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4903\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3434\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7500\n",
            "\n",
            "Start of epoch 199\n",
            "Training loss (for one batch) at step 0: 1.7313\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7003\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4208\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0045\n",
            "\n",
            "Start of epoch 200\n",
            "Training loss (for one batch) at step 0: 1.5241\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4107\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2993\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6763\n",
            "\n",
            "Start of epoch 201\n",
            "Training loss (for one batch) at step 0: 1.4133\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9443\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2455\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5382\n",
            "\n",
            "Start of epoch 202\n",
            "Training loss (for one batch) at step 0: 1.7661\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1980\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6176\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8281\n",
            "\n",
            "Start of epoch 203\n",
            "Training loss (for one batch) at step 0: 2.5274\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1420\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4589\n",
            "\n",
            "Start of epoch 204\n",
            "Training loss (for one batch) at step 0: 1.1610\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2404\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3872\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5247\n",
            "\n",
            "Start of epoch 205\n",
            "Training loss (for one batch) at step 0: 1.5004\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1602\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1912\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8043\n",
            "\n",
            "Start of epoch 206\n",
            "Training loss (for one batch) at step 0: 1.1419\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6582\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8802\n",
            "\n",
            "Start of epoch 207\n",
            "Training loss (for one batch) at step 0: 1.1486\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5686\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4718\n",
            "\n",
            "Start of epoch 208\n",
            "Training loss (for one batch) at step 0: 1.6342\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8676\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1581\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7279\n",
            "\n",
            "Start of epoch 209\n",
            "Training loss (for one batch) at step 0: 1.4201\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1753\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4650\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5408\n",
            "\n",
            "Start of epoch 210\n",
            "Training loss (for one batch) at step 0: 2.0306\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3694\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0977\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5936\n",
            "\n",
            "Start of epoch 211\n",
            "Training loss (for one batch) at step 0: 1.1710\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7979\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8288\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7373\n",
            "\n",
            "Start of epoch 212\n",
            "Training loss (for one batch) at step 0: 1.4247\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6138\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1916\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8556\n",
            "\n",
            "Start of epoch 213\n",
            "Training loss (for one batch) at step 0: 1.6685\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0517\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9004\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0057\n",
            "\n",
            "Start of epoch 214\n",
            "Training loss (for one batch) at step 0: 1.1675\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7493\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5520\n",
            "\n",
            "Start of epoch 215\n",
            "Training loss (for one batch) at step 0: 1.9681\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5390\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5282\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5489\n",
            "\n",
            "Start of epoch 216\n",
            "Training loss (for one batch) at step 0: 1.5627\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3311\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7309\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4782\n",
            "\n",
            "Start of epoch 217\n",
            "Training loss (for one batch) at step 0: 1.0881\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4274\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6518\n",
            "\n",
            "Start of epoch 218\n",
            "Training loss (for one batch) at step 0: 1.1505\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1095\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4586\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5308\n",
            "\n",
            "Start of epoch 219\n",
            "Training loss (for one batch) at step 0: 1.4217\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5730\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1680\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9606\n",
            "\n",
            "Start of epoch 220\n",
            "Training loss (for one batch) at step 0: 1.7102\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5805\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4664\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9041\n",
            "\n",
            "Start of epoch 221\n",
            "Training loss (for one batch) at step 0: 2.0214\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6408\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1013\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5126\n",
            "\n",
            "Start of epoch 222\n",
            "Training loss (for one batch) at step 0: 1.7058\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1907\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6507\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6381\n",
            "\n",
            "Start of epoch 223\n",
            "Training loss (for one batch) at step 0: 2.0680\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0803\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6644\n",
            "\n",
            "Start of epoch 224\n",
            "Training loss (for one batch) at step 0: 2.0887\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0862\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1276\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4600\n",
            "\n",
            "Start of epoch 225\n",
            "Training loss (for one batch) at step 0: 0.9864\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5884\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5791\n",
            "\n",
            "Start of epoch 226\n",
            "Training loss (for one batch) at step 0: 1.1171\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1208\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3653\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5071\n",
            "\n",
            "Start of epoch 227\n",
            "Training loss (for one batch) at step 0: 1.2902\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6406\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9858\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9708\n",
            "\n",
            "Start of epoch 228\n",
            "Training loss (for one batch) at step 0: 1.3273\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7363\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1534\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5640\n",
            "\n",
            "Start of epoch 229\n",
            "Training loss (for one batch) at step 0: 1.8327\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2014\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3209\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4992\n",
            "\n",
            "Start of epoch 230\n",
            "Training loss (for one batch) at step 0: 1.4680\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4277\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9093\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8009\n",
            "\n",
            "Start of epoch 231\n",
            "Training loss (for one batch) at step 0: 1.7398\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6237\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6705\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5087\n",
            "\n",
            "Start of epoch 232\n",
            "Training loss (for one batch) at step 0: 1.0849\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6997\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7431\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3990\n",
            "\n",
            "Start of epoch 233\n",
            "Training loss (for one batch) at step 0: 1.6792\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0293\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1508\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5327\n",
            "\n",
            "Start of epoch 234\n",
            "Training loss (for one batch) at step 0: 1.0545\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8214\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2894\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5241\n",
            "\n",
            "Start of epoch 235\n",
            "Training loss (for one batch) at step 0: 1.8038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3191\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1789\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6796\n",
            "\n",
            "Start of epoch 236\n",
            "Training loss (for one batch) at step 0: 1.4201\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8969\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4156\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5358\n",
            "\n",
            "Start of epoch 237\n",
            "Training loss (for one batch) at step 0: 1.1924\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8146\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9942\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7008\n",
            "\n",
            "Start of epoch 238\n",
            "Training loss (for one batch) at step 0: 1.0089\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1538\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3462\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6765\n",
            "\n",
            "Start of epoch 239\n",
            "Training loss (for one batch) at step 0: 1.4415\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3528\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8325\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0866\n",
            "\n",
            "Start of epoch 240\n",
            "Training loss (for one batch) at step 0: 1.4250\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3527\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7380\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6278\n",
            "\n",
            "Start of epoch 241\n",
            "Training loss (for one batch) at step 0: 1.2543\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1468\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1874\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7358\n",
            "\n",
            "Start of epoch 242\n",
            "Training loss (for one batch) at step 0: 1.1470\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1227\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6556\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4288\n",
            "\n",
            "Start of epoch 243\n",
            "Training loss (for one batch) at step 0: 1.6273\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9328\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1473\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5364\n",
            "\n",
            "Start of epoch 244\n",
            "Training loss (for one batch) at step 0: 0.9154\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1078\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6252\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6143\n",
            "\n",
            "Start of epoch 245\n",
            "Training loss (for one batch) at step 0: 1.1470\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1876\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4460\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1352\n",
            "\n",
            "Start of epoch 246\n",
            "Training loss (for one batch) at step 0: 1.1613\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0589\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9418\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4136\n",
            "\n",
            "Start of epoch 247\n",
            "Training loss (for one batch) at step 0: 1.1457\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3770\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5293\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6155\n",
            "\n",
            "Start of epoch 248\n",
            "Training loss (for one batch) at step 0: 1.1263\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0865\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5298\n",
            "\n",
            "Start of epoch 249\n",
            "Training loss (for one batch) at step 0: 1.1849\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1772\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9215\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5425\n",
            "\n",
            "Start of epoch 250\n",
            "Training loss (for one batch) at step 0: 1.0860\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3247\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2936\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8189\n",
            "\n",
            "Start of epoch 251\n",
            "Training loss (for one batch) at step 0: 1.4403\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5923\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5888\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8612\n",
            "\n",
            "Start of epoch 252\n",
            "Training loss (for one batch) at step 0: 1.3405\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1826\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0382\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5472\n",
            "\n",
            "Start of epoch 253\n",
            "Training loss (for one batch) at step 0: 1.0550\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1475\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1696\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7411\n",
            "\n",
            "Start of epoch 254\n",
            "Training loss (for one batch) at step 0: 0.9666\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1721\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8950\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8970\n",
            "\n",
            "Start of epoch 255\n",
            "Training loss (for one batch) at step 0: 1.1303\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6808\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5310\n",
            "\n",
            "Start of epoch 256\n",
            "Training loss (for one batch) at step 0: 1.3394\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9184\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3971\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5187\n",
            "\n",
            "Start of epoch 257\n",
            "Training loss (for one batch) at step 0: 1.5470\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1058\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7107\n",
            "\n",
            "Start of epoch 258\n",
            "Training loss (for one batch) at step 0: 1.0473\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0863\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9934\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5185\n",
            "\n",
            "Start of epoch 259\n",
            "Training loss (for one batch) at step 0: 1.5171\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3244\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0403\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4506\n",
            "\n",
            "Start of epoch 260\n",
            "Training loss (for one batch) at step 0: 1.5940\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4362\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3246\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4772\n",
            "\n",
            "Start of epoch 261\n",
            "Training loss (for one batch) at step 0: 1.6792\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1441\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1441\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6709\n",
            "\n",
            "Start of epoch 262\n",
            "Training loss (for one batch) at step 0: 1.0176\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9018\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8008\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4639\n",
            "\n",
            "Start of epoch 263\n",
            "Training loss (for one batch) at step 0: 1.0117\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1248\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0396\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5004\n",
            "\n",
            "Start of epoch 264\n",
            "Training loss (for one batch) at step 0: 1.7429\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0626\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3576\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5442\n",
            "\n",
            "Start of epoch 265\n",
            "Training loss (for one batch) at step 0: 0.9516\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4613\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7537\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4967\n",
            "\n",
            "Start of epoch 266\n",
            "Training loss (for one batch) at step 0: 1.1980\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5341\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4904\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7069\n",
            "\n",
            "Start of epoch 267\n",
            "Training loss (for one batch) at step 0: 1.3973\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2196\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6956\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8562\n",
            "\n",
            "Start of epoch 268\n",
            "Training loss (for one batch) at step 0: 1.4846\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7656\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3676\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3868\n",
            "\n",
            "Start of epoch 269\n",
            "Training loss (for one batch) at step 0: 0.9362\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6891\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0725\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7263\n",
            "\n",
            "Start of epoch 270\n",
            "Training loss (for one batch) at step 0: 1.0702\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4442\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9220\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4708\n",
            "\n",
            "Start of epoch 271\n",
            "Training loss (for one batch) at step 0: 0.9643\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1731\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0726\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4826\n",
            "\n",
            "Start of epoch 272\n",
            "Training loss (for one batch) at step 0: 1.6840\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6247\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4757\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6752\n",
            "\n",
            "Start of epoch 273\n",
            "Training loss (for one batch) at step 0: 1.0954\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0279\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4802\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8485\n",
            "\n",
            "Start of epoch 274\n",
            "Training loss (for one batch) at step 0: 2.0848\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7729\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9111\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4243\n",
            "\n",
            "Start of epoch 275\n",
            "Training loss (for one batch) at step 0: 1.1345\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5147\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4823\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0828\n",
            "\n",
            "Start of epoch 276\n",
            "Training loss (for one batch) at step 0: 1.8700\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2696\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7113\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7648\n",
            "\n",
            "Start of epoch 277\n",
            "Training loss (for one batch) at step 0: 1.6990\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1334\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6987\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2840\n",
            "\n",
            "Start of epoch 278\n",
            "Training loss (for one batch) at step 0: 1.1209\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6264\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8484\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7605\n",
            "\n",
            "Start of epoch 279\n",
            "Training loss (for one batch) at step 0: 1.2735\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7704\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1737\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5743\n",
            "\n",
            "Start of epoch 280\n",
            "Training loss (for one batch) at step 0: 1.6161\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2212\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8397\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4750\n",
            "\n",
            "Start of epoch 281\n",
            "Training loss (for one batch) at step 0: 1.3000\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2756\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1122\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9427\n",
            "\n",
            "Start of epoch 282\n",
            "Training loss (for one batch) at step 0: 1.2188\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9062\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9190\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8048\n",
            "\n",
            "Start of epoch 283\n",
            "Training loss (for one batch) at step 0: 1.0105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1301\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4545\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8578\n",
            "\n",
            "Start of epoch 284\n",
            "Training loss (for one batch) at step 0: 1.4005\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4448\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0215\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4795\n",
            "\n",
            "Start of epoch 285\n",
            "Training loss (for one batch) at step 0: 1.6513\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5736\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6743\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9060\n",
            "\n",
            "Start of epoch 286\n",
            "Training loss (for one batch) at step 0: 1.2402\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4326\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4779\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5255\n",
            "\n",
            "Start of epoch 287\n",
            "Training loss (for one batch) at step 0: 1.8571\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0153\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9848\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4610\n",
            "\n",
            "Start of epoch 288\n",
            "Training loss (for one batch) at step 0: 1.0283\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0449\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9639\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8516\n",
            "\n",
            "Start of epoch 289\n",
            "Training loss (for one batch) at step 0: 1.9444\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2315\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0209\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6958\n",
            "\n",
            "Start of epoch 290\n",
            "Training loss (for one batch) at step 0: 1.1639\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6321\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1850\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5753\n",
            "\n",
            "Start of epoch 291\n",
            "Training loss (for one batch) at step 0: 1.0004\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4769\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2605\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5110\n",
            "\n",
            "Start of epoch 292\n",
            "Training loss (for one batch) at step 0: 1.5343\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9383\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9556\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1267\n",
            "\n",
            "Start of epoch 293\n",
            "Training loss (for one batch) at step 0: 1.0197\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8400\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1090\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7791\n",
            "\n",
            "Start of epoch 294\n",
            "Training loss (for one batch) at step 0: 1.0362\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8903\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3882\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4384\n",
            "\n",
            "Start of epoch 295\n",
            "Training loss (for one batch) at step 0: 2.0924\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7608\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4933\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4184\n",
            "\n",
            "Start of epoch 296\n",
            "Training loss (for one batch) at step 0: 1.2725\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4514\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4690\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6719\n",
            "\n",
            "Start of epoch 297\n",
            "Training loss (for one batch) at step 0: 0.9418\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9080\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8187\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6156\n",
            "\n",
            "Start of epoch 298\n",
            "Training loss (for one batch) at step 0: 1.1810\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9697\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5668\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1753\n",
            "\n",
            "Start of epoch 299\n",
            "Training loss (for one batch) at step 0: 1.1126\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8169\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9878\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4992\n",
            "\n",
            "Start of epoch 300\n",
            "Training loss (for one batch) at step 0: 0.9076\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0177\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1866\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8224\n",
            "\n",
            "Start of epoch 301\n",
            "Training loss (for one batch) at step 0: 1.1079\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5254\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1118\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6746\n",
            "\n",
            "Start of epoch 302\n",
            "Training loss (for one batch) at step 0: 1.8041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8633\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1004\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7535\n",
            "\n",
            "Start of epoch 303\n",
            "Training loss (for one batch) at step 0: 1.5993\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9165\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4309\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3854\n",
            "\n",
            "Start of epoch 304\n",
            "Training loss (for one batch) at step 0: 1.7632\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8466\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1070\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5250\n",
            "\n",
            "Start of epoch 305\n",
            "Training loss (for one batch) at step 0: 1.3081\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1877\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3817\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8215\n",
            "\n",
            "Start of epoch 306\n",
            "Training loss (for one batch) at step 0: 1.6230\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8918\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1534\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7835\n",
            "\n",
            "Start of epoch 307\n",
            "Training loss (for one batch) at step 0: 1.0306\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3627\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3299\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4562\n",
            "\n",
            "Start of epoch 308\n",
            "Training loss (for one batch) at step 0: 1.0783\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4926\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4627\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8335\n",
            "\n",
            "Start of epoch 309\n",
            "Training loss (for one batch) at step 0: 0.9892\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9722\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2410\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6870\n",
            "\n",
            "Start of epoch 310\n",
            "Training loss (for one batch) at step 0: 1.0242\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9214\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3798\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6598\n",
            "\n",
            "Start of epoch 311\n",
            "Training loss (for one batch) at step 0: 1.8355\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0411\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2217\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7597\n",
            "\n",
            "Start of epoch 312\n",
            "Training loss (for one batch) at step 0: 0.9568\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7203\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0623\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6106\n",
            "\n",
            "Start of epoch 313\n",
            "Training loss (for one batch) at step 0: 0.8595\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1486\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1353\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4866\n",
            "\n",
            "Start of epoch 314\n",
            "Training loss (for one batch) at step 0: 1.6773\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5009\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1954\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4200\n",
            "\n",
            "Start of epoch 315\n",
            "Training loss (for one batch) at step 0: 1.1356\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1100\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2005\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5269\n",
            "\n",
            "Start of epoch 316\n",
            "Training loss (for one batch) at step 0: 1.2708\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0253\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0550\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4671\n",
            "\n",
            "Start of epoch 317\n",
            "Training loss (for one batch) at step 0: 1.0903\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3162\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6139\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5278\n",
            "\n",
            "Start of epoch 318\n",
            "Training loss (for one batch) at step 0: 1.7755\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2370\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2520\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7242\n",
            "\n",
            "Start of epoch 319\n",
            "Training loss (for one batch) at step 0: 1.2066\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4384\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1990\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7244\n",
            "\n",
            "Start of epoch 320\n",
            "Training loss (for one batch) at step 0: 1.1684\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9071\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9342\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3757\n",
            "\n",
            "Start of epoch 321\n",
            "Training loss (for one batch) at step 0: 1.2251\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2226\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4275\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3999\n",
            "\n",
            "Start of epoch 322\n",
            "Training loss (for one batch) at step 0: 1.7449\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5624\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8710\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0456\n",
            "\n",
            "Start of epoch 323\n",
            "Training loss (for one batch) at step 0: 1.1912\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3555\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0662\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0094\n",
            "\n",
            "Start of epoch 324\n",
            "Training loss (for one batch) at step 0: 1.3711\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8252\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3788\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5390\n",
            "\n",
            "Start of epoch 325\n",
            "Training loss (for one batch) at step 0: 1.2275\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1571\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9983\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3404\n",
            "\n",
            "Start of epoch 326\n",
            "Training loss (for one batch) at step 0: 1.4066\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9420\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8436\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5114\n",
            "\n",
            "Start of epoch 327\n",
            "Training loss (for one batch) at step 0: 1.0366\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3482\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0471\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6705\n",
            "\n",
            "Start of epoch 328\n",
            "Training loss (for one batch) at step 0: 1.5188\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0448\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1707\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5561\n",
            "\n",
            "Start of epoch 329\n",
            "Training loss (for one batch) at step 0: 1.5176\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0623\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7771\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3459\n",
            "\n",
            "Start of epoch 330\n",
            "Training loss (for one batch) at step 0: 1.1184\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4012\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9618\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6119\n",
            "\n",
            "Start of epoch 331\n",
            "Training loss (for one batch) at step 0: 0.9675\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0920\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2488\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6785\n",
            "\n",
            "Start of epoch 332\n",
            "Training loss (for one batch) at step 0: 1.0731\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2162\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7644\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6396\n",
            "\n",
            "Start of epoch 333\n",
            "Training loss (for one batch) at step 0: 0.9082\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0101\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9323\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4490\n",
            "\n",
            "Start of epoch 334\n",
            "Training loss (for one batch) at step 0: 1.0625\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9198\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3977\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8310\n",
            "\n",
            "Start of epoch 335\n",
            "Training loss (for one batch) at step 0: 1.2779\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9850\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0580\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4406\n",
            "\n",
            "Start of epoch 336\n",
            "Training loss (for one batch) at step 0: 0.9657\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0417\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2920\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4653\n",
            "\n",
            "Start of epoch 337\n",
            "Training loss (for one batch) at step 0: 0.9237\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8208\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7539\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5818\n",
            "\n",
            "Start of epoch 338\n",
            "Training loss (for one batch) at step 0: 1.3204\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9609\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1750\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6191\n",
            "\n",
            "Start of epoch 339\n",
            "Training loss (for one batch) at step 0: 1.0133\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0467\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2725\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5798\n",
            "\n",
            "Start of epoch 340\n",
            "Training loss (for one batch) at step 0: 1.2286\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0520\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0213\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6912\n",
            "\n",
            "Start of epoch 341\n",
            "Training loss (for one batch) at step 0: 1.4850\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0583\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9205\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5699\n",
            "\n",
            "Start of epoch 342\n",
            "Training loss (for one batch) at step 0: 1.4837\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8711\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3626\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6167\n",
            "\n",
            "Start of epoch 343\n",
            "Training loss (for one batch) at step 0: 1.2277\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0521\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6818\n",
            "\n",
            "Start of epoch 344\n",
            "Training loss (for one batch) at step 0: 1.8208\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8176\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6402\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5659\n",
            "\n",
            "Start of epoch 345\n",
            "Training loss (for one batch) at step 0: 1.2663\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9556\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0120\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5747\n",
            "\n",
            "Start of epoch 346\n",
            "Training loss (for one batch) at step 0: 0.9713\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9532\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9586\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5007\n",
            "\n",
            "Start of epoch 347\n",
            "Training loss (for one batch) at step 0: 1.5372\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8552\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1020\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7694\n",
            "\n",
            "Start of epoch 348\n",
            "Training loss (for one batch) at step 0: 0.9532\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7893\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6194\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7498\n",
            "\n",
            "Start of epoch 349\n",
            "Training loss (for one batch) at step 0: 0.9102\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2006\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0896\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5489\n",
            "\n",
            "Start of epoch 350\n",
            "Training loss (for one batch) at step 0: 1.0996\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2880\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1245\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5563\n",
            "\n",
            "Start of epoch 351\n",
            "Training loss (for one batch) at step 0: 1.5584\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5321\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0237\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3548\n",
            "\n",
            "Start of epoch 352\n",
            "Training loss (for one batch) at step 0: 1.2887\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0917\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3296\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5130\n",
            "\n",
            "Start of epoch 353\n",
            "Training loss (for one batch) at step 0: 0.7151\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2381\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5520\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3609\n",
            "\n",
            "Start of epoch 354\n",
            "Training loss (for one batch) at step 0: 1.2119\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0362\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6851\n",
            "\n",
            "Start of epoch 355\n",
            "Training loss (for one batch) at step 0: 0.8931\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8090\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3583\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4550\n",
            "\n",
            "Start of epoch 356\n",
            "Training loss (for one batch) at step 0: 1.4331\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5592\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2449\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3444\n",
            "\n",
            "Start of epoch 357\n",
            "Training loss (for one batch) at step 0: 1.7261\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6303\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2860\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9349\n",
            "\n",
            "Start of epoch 358\n",
            "Training loss (for one batch) at step 0: 0.9163\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6943\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9316\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3928\n",
            "\n",
            "Start of epoch 359\n",
            "Training loss (for one batch) at step 0: 0.7171\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4729\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5055\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5577\n",
            "\n",
            "Start of epoch 360\n",
            "Training loss (for one batch) at step 0: 1.4206\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1174\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9412\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5591\n",
            "\n",
            "Start of epoch 361\n",
            "Training loss (for one batch) at step 0: 1.0147\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9809\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1233\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3846\n",
            "\n",
            "Start of epoch 362\n",
            "Training loss (for one batch) at step 0: 1.0664\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2461\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1203\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4934\n",
            "\n",
            "Start of epoch 363\n",
            "Training loss (for one batch) at step 0: 0.8763\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8897\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9788\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6830\n",
            "\n",
            "Start of epoch 364\n",
            "Training loss (for one batch) at step 0: 1.0316\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9649\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0382\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5154\n",
            "\n",
            "Start of epoch 365\n",
            "Training loss (for one batch) at step 0: 0.9693\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1268\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8590\n",
            "\n",
            "Start of epoch 366\n",
            "Training loss (for one batch) at step 0: 1.2605\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5077\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2240\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9506\n",
            "\n",
            "Start of epoch 367\n",
            "Training loss (for one batch) at step 0: 1.0169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0550\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9331\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8028\n",
            "\n",
            "Start of epoch 368\n",
            "Training loss (for one batch) at step 0: 1.1354\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1987\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1206\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5215\n",
            "\n",
            "Start of epoch 369\n",
            "Training loss (for one batch) at step 0: 0.9417\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1751\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2005\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5127\n",
            "\n",
            "Start of epoch 370\n",
            "Training loss (for one batch) at step 0: 1.1057\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2007\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3648\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5719\n",
            "\n",
            "Start of epoch 371\n",
            "Training loss (for one batch) at step 0: 1.1105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2433\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8895\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4478\n",
            "\n",
            "Start of epoch 372\n",
            "Training loss (for one batch) at step 0: 0.9318\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5834\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3603\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7418\n",
            "\n",
            "Start of epoch 373\n",
            "Training loss (for one batch) at step 0: 1.0856\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0369\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1308\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8124\n",
            "\n",
            "Start of epoch 374\n",
            "Training loss (for one batch) at step 0: 0.9150\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0435\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3371\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7224\n",
            "\n",
            "Start of epoch 375\n",
            "Training loss (for one batch) at step 0: 1.3510\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0084\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9966\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5202\n",
            "\n",
            "Start of epoch 376\n",
            "Training loss (for one batch) at step 0: 0.9775\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9767\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7216\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5577\n",
            "\n",
            "Start of epoch 377\n",
            "Training loss (for one batch) at step 0: 1.2224\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0636\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6299\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5165\n",
            "\n",
            "Start of epoch 378\n",
            "Training loss (for one batch) at step 0: 1.1522\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7621\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0721\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9443\n",
            "\n",
            "Start of epoch 379\n",
            "Training loss (for one batch) at step 0: 1.0974\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2017\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8485\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6398\n",
            "\n",
            "Start of epoch 380\n",
            "Training loss (for one batch) at step 0: 1.1565\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4887\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3179\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4672\n",
            "\n",
            "Start of epoch 381\n",
            "Training loss (for one batch) at step 0: 0.9413\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0228\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0946\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5335\n",
            "\n",
            "Start of epoch 382\n",
            "Training loss (for one batch) at step 0: 0.9123\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8699\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3693\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4336\n",
            "\n",
            "Start of epoch 383\n",
            "Training loss (for one batch) at step 0: 1.3943\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0687\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0259\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5234\n",
            "\n",
            "Start of epoch 384\n",
            "Training loss (for one batch) at step 0: 0.9197\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8428\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2440\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4046\n",
            "\n",
            "Start of epoch 385\n",
            "Training loss (for one batch) at step 0: 1.0915\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0839\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2142\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5659\n",
            "\n",
            "Start of epoch 386\n",
            "Training loss (for one batch) at step 0: 0.8615\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9455\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4704\n",
            "\n",
            "Start of epoch 387\n",
            "Training loss (for one batch) at step 0: 1.3311\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9144\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0614\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5402\n",
            "\n",
            "Start of epoch 388\n",
            "Training loss (for one batch) at step 0: 0.9193\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9966\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8109\n",
            "\n",
            "Start of epoch 389\n",
            "Training loss (for one batch) at step 0: 1.0527\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8756\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1019\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6423\n",
            "\n",
            "Start of epoch 390\n",
            "Training loss (for one batch) at step 0: 1.0100\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3642\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1826\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4909\n",
            "\n",
            "Start of epoch 391\n",
            "Training loss (for one batch) at step 0: 1.3555\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0718\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9134\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5682\n",
            "\n",
            "Start of epoch 392\n",
            "Training loss (for one batch) at step 0: 1.6946\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0889\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5312\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6245\n",
            "\n",
            "Start of epoch 393\n",
            "Training loss (for one batch) at step 0: 0.9679\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5237\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7713\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6586\n",
            "\n",
            "Start of epoch 394\n",
            "Training loss (for one batch) at step 0: 1.1529\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1629\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7352\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6775\n",
            "\n",
            "Start of epoch 395\n",
            "Training loss (for one batch) at step 0: 1.4569\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3359\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0858\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5163\n",
            "\n",
            "Start of epoch 396\n",
            "Training loss (for one batch) at step 0: 1.0327\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2814\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1777\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6318\n",
            "\n",
            "Start of epoch 397\n",
            "Training loss (for one batch) at step 0: 1.6688\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1860\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0120\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3971\n",
            "\n",
            "Start of epoch 398\n",
            "Training loss (for one batch) at step 0: 1.5007\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0486\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0618\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4426\n",
            "\n",
            "Start of epoch 399\n",
            "Training loss (for one batch) at step 0: 0.8744\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1479\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3882\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3969\n",
            "\n",
            "Start of epoch 400\n",
            "Training loss (for one batch) at step 0: 1.6527\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2776\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8784\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7975\n",
            "\n",
            "Start of epoch 401\n",
            "Training loss (for one batch) at step 0: 1.1392\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9414\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9904\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4252\n",
            "\n",
            "Start of epoch 402\n",
            "Training loss (for one batch) at step 0: 1.0349\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7762\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9813\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4893\n",
            "\n",
            "Start of epoch 403\n",
            "Training loss (for one batch) at step 0: 0.8505\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8662\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4992\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5220\n",
            "\n",
            "Start of epoch 404\n",
            "Training loss (for one batch) at step 0: 1.1116\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0972\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7455\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5720\n",
            "\n",
            "Start of epoch 405\n",
            "Training loss (for one batch) at step 0: 0.9029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9968\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0544\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5284\n",
            "\n",
            "Start of epoch 406\n",
            "Training loss (for one batch) at step 0: 1.2278\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2001\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9204\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3489\n",
            "\n",
            "Start of epoch 407\n",
            "Training loss (for one batch) at step 0: 1.1333\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8311\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5711\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3939\n",
            "\n",
            "Start of epoch 408\n",
            "Training loss (for one batch) at step 0: 0.9732\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0018\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9824\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5382\n",
            "\n",
            "Start of epoch 409\n",
            "Training loss (for one batch) at step 0: 1.2045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8822\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2299\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8374\n",
            "\n",
            "Start of epoch 410\n",
            "Training loss (for one batch) at step 0: 1.1802\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8067\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6856\n",
            "\n",
            "Start of epoch 411\n",
            "Training loss (for one batch) at step 0: 1.3680\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0312\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8097\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.2970\n",
            "\n",
            "Start of epoch 412\n",
            "Training loss (for one batch) at step 0: 0.8229\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9559\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3680\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8807\n",
            "\n",
            "Start of epoch 413\n",
            "Training loss (for one batch) at step 0: 1.1035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8157\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3543\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5444\n",
            "\n",
            "Start of epoch 414\n",
            "Training loss (for one batch) at step 0: 0.8274\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9756\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8193\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0134\n",
            "\n",
            "Start of epoch 415\n",
            "Training loss (for one batch) at step 0: 1.0250\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2226\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7711\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4654\n",
            "\n",
            "Start of epoch 416\n",
            "Training loss (for one batch) at step 0: 1.5044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0106\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1428\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5418\n",
            "\n",
            "Start of epoch 417\n",
            "Training loss (for one batch) at step 0: 0.8701\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2370\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0368\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4906\n",
            "\n",
            "Start of epoch 418\n",
            "Training loss (for one batch) at step 0: 1.1084\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5721\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8213\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5382\n",
            "\n",
            "Start of epoch 419\n",
            "Training loss (for one batch) at step 0: 1.0163\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6551\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2735\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3708\n",
            "\n",
            "Start of epoch 420\n",
            "Training loss (for one batch) at step 0: 1.1407\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7903\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1810\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7612\n",
            "\n",
            "Start of epoch 421\n",
            "Training loss (for one batch) at step 0: 1.0865\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0356\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7731\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5222\n",
            "\n",
            "Start of epoch 422\n",
            "Training loss (for one batch) at step 0: 0.9651\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7948\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2703\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7329\n",
            "\n",
            "Start of epoch 423\n",
            "Training loss (for one batch) at step 0: 1.2832\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3310\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4419\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3863\n",
            "\n",
            "Start of epoch 424\n",
            "Training loss (for one batch) at step 0: 0.8162\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8566\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0255\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7539\n",
            "\n",
            "Start of epoch 425\n",
            "Training loss (for one batch) at step 0: 1.1253\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0695\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0502\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4836\n",
            "\n",
            "Start of epoch 426\n",
            "Training loss (for one batch) at step 0: 1.3557\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1415\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0371\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5835\n",
            "\n",
            "Start of epoch 427\n",
            "Training loss (for one batch) at step 0: 1.2326\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0699\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0892\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6017\n",
            "\n",
            "Start of epoch 428\n",
            "Training loss (for one batch) at step 0: 1.8825\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0395\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3605\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5126\n",
            "\n",
            "Start of epoch 429\n",
            "Training loss (for one batch) at step 0: 1.2401\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8583\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0287\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7212\n",
            "\n",
            "Start of epoch 430\n",
            "Training loss (for one batch) at step 0: 0.9551\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8367\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7757\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4516\n",
            "\n",
            "Start of epoch 431\n",
            "Training loss (for one batch) at step 0: 0.8608\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9423\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8192\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6040\n",
            "\n",
            "Start of epoch 432\n",
            "Training loss (for one batch) at step 0: 1.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8778\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2629\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5356\n",
            "\n",
            "Start of epoch 433\n",
            "Training loss (for one batch) at step 0: 1.8998\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8527\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0299\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6202\n",
            "\n",
            "Start of epoch 434\n",
            "Training loss (for one batch) at step 0: 0.8514\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5388\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6925\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5556\n",
            "\n",
            "Start of epoch 435\n",
            "Training loss (for one batch) at step 0: 0.8504\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0156\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0959\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5529\n",
            "\n",
            "Start of epoch 436\n",
            "Training loss (for one batch) at step 0: 0.8274\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2183\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4363\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4726\n",
            "\n",
            "Start of epoch 437\n",
            "Training loss (for one batch) at step 0: 1.1923\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7582\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1515\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3917\n",
            "\n",
            "Start of epoch 438\n",
            "Training loss (for one batch) at step 0: 1.4841\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9767\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9488\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5029\n",
            "\n",
            "Start of epoch 439\n",
            "Training loss (for one batch) at step 0: 1.5054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1366\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8214\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4955\n",
            "\n",
            "Start of epoch 440\n",
            "Training loss (for one batch) at step 0: 0.9233\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1709\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0002\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6121\n",
            "\n",
            "Start of epoch 441\n",
            "Training loss (for one batch) at step 0: 0.8647\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8080\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0506\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9343\n",
            "\n",
            "Start of epoch 442\n",
            "Training loss (for one batch) at step 0: 1.2193\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8311\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0545\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5218\n",
            "\n",
            "Start of epoch 443\n",
            "Training loss (for one batch) at step 0: 1.0734\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9780\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2458\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5442\n",
            "\n",
            "Start of epoch 444\n",
            "Training loss (for one batch) at step 0: 1.7045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0974\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3697\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3712\n",
            "\n",
            "Start of epoch 445\n",
            "Training loss (for one batch) at step 0: 0.9497\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0380\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0627\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5772\n",
            "\n",
            "Start of epoch 446\n",
            "Training loss (for one batch) at step 0: 1.1348\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4747\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0819\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0944\n",
            "\n",
            "Start of epoch 447\n",
            "Training loss (for one batch) at step 0: 0.9507\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9425\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1407\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4575\n",
            "\n",
            "Start of epoch 448\n",
            "Training loss (for one batch) at step 0: 1.1352\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2383\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9728\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8053\n",
            "\n",
            "Start of epoch 449\n",
            "Training loss (for one batch) at step 0: 1.0124\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7853\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8005\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5413\n",
            "\n",
            "Start of epoch 450\n",
            "Training loss (for one batch) at step 0: 1.0336\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0364\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8188\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7649\n",
            "\n",
            "Start of epoch 451\n",
            "Training loss (for one batch) at step 0: 1.1922\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1606\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2647\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6287\n",
            "\n",
            "Start of epoch 452\n",
            "Training loss (for one batch) at step 0: 0.8677\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1313\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0695\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5896\n",
            "\n",
            "Start of epoch 453\n",
            "Training loss (for one batch) at step 0: 1.1679\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9583\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8990\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6686\n",
            "\n",
            "Start of epoch 454\n",
            "Training loss (for one batch) at step 0: 0.7080\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2479\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7848\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5383\n",
            "\n",
            "Start of epoch 455\n",
            "Training loss (for one batch) at step 0: 0.7806\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0855\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3469\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9253\n",
            "\n",
            "Start of epoch 456\n",
            "Training loss (for one batch) at step 0: 1.0288\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8350\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7727\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5873\n",
            "\n",
            "Start of epoch 457\n",
            "Training loss (for one batch) at step 0: 0.7889\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9099\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2248\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7736\n",
            "\n",
            "Start of epoch 458\n",
            "Training loss (for one batch) at step 0: 0.8808\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5092\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3949\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4182\n",
            "\n",
            "Start of epoch 459\n",
            "Training loss (for one batch) at step 0: 1.0107\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1985\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8969\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4412\n",
            "\n",
            "Start of epoch 460\n",
            "Training loss (for one batch) at step 0: 1.2078\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1311\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0335\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7938\n",
            "\n",
            "Start of epoch 461\n",
            "Training loss (for one batch) at step 0: 0.8013\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9723\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3886\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4660\n",
            "\n",
            "Start of epoch 462\n",
            "Training loss (for one batch) at step 0: 0.8806\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0654\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8606\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5197\n",
            "\n",
            "Start of epoch 463\n",
            "Training loss (for one batch) at step 0: 0.9066\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8799\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3839\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5195\n",
            "\n",
            "Start of epoch 464\n",
            "Training loss (for one batch) at step 0: 0.9470\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2465\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1078\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4936\n",
            "\n",
            "Start of epoch 465\n",
            "Training loss (for one batch) at step 0: 1.0387\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0161\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5456\n",
            "\n",
            "Start of epoch 466\n",
            "Training loss (for one batch) at step 0: 0.7405\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0543\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9631\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5566\n",
            "\n",
            "Start of epoch 467\n",
            "Training loss (for one batch) at step 0: 1.1145\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7328\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8513\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8937\n",
            "\n",
            "Start of epoch 468\n",
            "Training loss (for one batch) at step 0: 1.3115\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5368\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7833\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3510\n",
            "\n",
            "Start of epoch 469\n",
            "Training loss (for one batch) at step 0: 0.8295\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9616\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0095\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3183\n",
            "\n",
            "Start of epoch 470\n",
            "Training loss (for one batch) at step 0: 0.6859\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3303\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7469\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6974\n",
            "\n",
            "Start of epoch 471\n",
            "Training loss (for one batch) at step 0: 0.9762\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9601\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0989\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5365\n",
            "\n",
            "Start of epoch 472\n",
            "Training loss (for one batch) at step 0: 0.8346\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7907\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2077\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3765\n",
            "\n",
            "Start of epoch 473\n",
            "Training loss (for one batch) at step 0: 1.0134\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1757\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3105\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5479\n",
            "\n",
            "Start of epoch 474\n",
            "Training loss (for one batch) at step 0: 2.0248\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8781\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9519\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6025\n",
            "\n",
            "Start of epoch 475\n",
            "Training loss (for one batch) at step 0: 1.2350\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4135\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9535\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3728\n",
            "\n",
            "Start of epoch 476\n",
            "Training loss (for one batch) at step 0: 0.8403\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2684\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9436\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6201\n",
            "\n",
            "Start of epoch 477\n",
            "Training loss (for one batch) at step 0: 1.1351\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4248\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3221\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6869\n",
            "\n",
            "Start of epoch 478\n",
            "Training loss (for one batch) at step 0: 1.4963\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2521\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2475\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4966\n",
            "\n",
            "Start of epoch 479\n",
            "Training loss (for one batch) at step 0: 1.0235\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7938\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4361\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5893\n",
            "\n",
            "Start of epoch 480\n",
            "Training loss (for one batch) at step 0: 1.3436\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1482\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4789\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.2909\n",
            "\n",
            "Start of epoch 481\n",
            "Training loss (for one batch) at step 0: 1.4202\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9067\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3154\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4797\n",
            "\n",
            "Start of epoch 482\n",
            "Training loss (for one batch) at step 0: 1.1716\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9388\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0347\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5565\n",
            "\n",
            "Start of epoch 483\n",
            "Training loss (for one batch) at step 0: 0.9222\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1822\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0486\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4908\n",
            "\n",
            "Start of epoch 484\n",
            "Training loss (for one batch) at step 0: 1.0233\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.6895\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0164\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4840\n",
            "\n",
            "Start of epoch 485\n",
            "Training loss (for one batch) at step 0: 0.9221\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1161\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6061\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5853\n",
            "\n",
            "Start of epoch 486\n",
            "Training loss (for one batch) at step 0: 0.9338\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2102\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0171\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7015\n",
            "\n",
            "Start of epoch 487\n",
            "Training loss (for one batch) at step 0: 1.1251\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2998\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7843\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7022\n",
            "\n",
            "Start of epoch 488\n",
            "Training loss (for one batch) at step 0: 0.7387\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5471\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8860\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3853\n",
            "\n",
            "Start of epoch 489\n",
            "Training loss (for one batch) at step 0: 1.1437\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5259\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2007\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5000\n",
            "\n",
            "Start of epoch 490\n",
            "Training loss (for one batch) at step 0: 1.1914\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8323\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4354\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5349\n",
            "\n",
            "Start of epoch 491\n",
            "Training loss (for one batch) at step 0: 0.8718\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7723\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9562\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6737\n",
            "\n",
            "Start of epoch 492\n",
            "Training loss (for one batch) at step 0: 0.7595\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7371\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6944\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5318\n",
            "\n",
            "Start of epoch 493\n",
            "Training loss (for one batch) at step 0: 0.8026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7961\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0246\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5975\n",
            "\n",
            "Start of epoch 494\n",
            "Training loss (for one batch) at step 0: 0.8169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7767\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8489\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5915\n",
            "\n",
            "Start of epoch 495\n",
            "Training loss (for one batch) at step 0: 0.7931\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9242\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7842\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6195\n",
            "\n",
            "Start of epoch 496\n",
            "Training loss (for one batch) at step 0: 1.2665\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3208\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.5973\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8373\n",
            "\n",
            "Start of epoch 497\n",
            "Training loss (for one batch) at step 0: 0.7245\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8979\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9163\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9832\n",
            "\n",
            "Start of epoch 498\n",
            "Training loss (for one batch) at step 0: 1.7396\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0098\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9701\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5009\n",
            "\n",
            "Start of epoch 499\n",
            "Training loss (for one batch) at step 0: 1.3070\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7533\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1341\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy_8SvQ-pAey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "performance = pd.DataFrame()\n",
        "performance['training_mse'] = training_mse\n",
        "performance['valid_mse'] = valid_mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_L5YRTpdTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ef5de82f-5ce6-4f4d-b2cd-b76bb5d127a9"
      },
      "source": [
        "performance.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe123fee9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UkV66dgmlyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ae242d18-70f6-42d6-c55f-fe47a848c786"
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "f1, f2, f3 = prediction.T\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(f1, f2, f3, 'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fe122e675c0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZKPk2l1krmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape = (3,))\n",
        "x1 = layers.Dense(10, activation=\"relu\")(inputs)\n",
        "x2 = layers.Dense(10, activation='relu')(x1)\n",
        "outputs = layers.Dense(3, activation='linear')(x2)\n",
        "model = keras.Model(inputs = inputs, outputs = outputs)\n",
        "epochs = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqPagbGMkovO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98719d54-d23b-4e75-dd7f-8749021e3abd"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "    # open a GradientTape to record the operations run during the feed forward\n",
        "    # enables aoto-partial-Differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "      # run the feed foward process of the layers.\n",
        "      # the operations that the layers apply to its inpurts and going to bee recorded on the GradientTape\n",
        "      linear = model(x_batch_train, training = True)\n",
        "      # print(linear)\n",
        "      # compute the loss value for this minibatch\n",
        "      # mse = Keras_loss_function(y_batch_train, linear)\n",
        "      mse = tf.keras.losses.MSE(y_batch_train, linear)\n",
        "      reconstruction_error = tf.reduce_mean(mse)\n",
        "      \n",
        "      # print(mse)\n",
        "      # mse = keras.losses.mean_squared_error(y_batch_train, linear) # mse gives 3 number\n",
        "    # print(mse)\n",
        "    # use the gradient tap to automatically retrieve the gradients of the \n",
        "    # trainable variables with respect to the loss\n",
        "    grads = tape.gradient(mse, model.trainable_weights)\n",
        "    # print(grads)\n",
        "    # weight + bias for every layer\n",
        "    # run one step of gradient dscent by updating the value of the variables to minize the loss\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    # print(model.trainable_weights,'\\n')\n",
        "    # print log information every 10 batches.\n",
        "    if step % 10 == 0:\n",
        "      print(\n",
        "          \"Training loss (for one batch) at step %d: %.4f\"\n",
        "          %(step, float(reconstruction_error))\n",
        "      )\n",
        "      print(\"seen so far: %s samples\" % ((step +1) * 100))\n",
        "\n",
        "\n",
        "  # Run a validation loop at the end of each epoch\n",
        "  for x_batch_val, y_batch_val in val_dataset:\n",
        "    val_linear = model(x_batch_val, training = False)\n",
        "    val_mse = tf.keras.losses.MSE(y_batch_val, val_linear)\n",
        "    val_reconstruction_error = tf.reduce_mean(val_mse)\n",
        "  # print MSE for validation set\n",
        "  print(\"validation MSE: %.4f\" % (float(val_reconstruction_error)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.4174\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.2493\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.1747\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.1148\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.1511\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.1101\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0652\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0607\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 0.0646\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0418\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0365\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0339\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.0348\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0372\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0289\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0280\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.0268\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0322\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0244\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0232\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 0.0267\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0283\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0190\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0293\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 0.0251\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0271\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0269\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0247\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 0.0209\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0251\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0275\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0255\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 0.0223\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0196\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0211\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0201\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 0.0205\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0175\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0166\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0171\n",
            "\n",
            "Start of epoch 10\n",
            "Training loss (for one batch) at step 0: 0.0169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0215\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0165\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0219\n",
            "\n",
            "Start of epoch 11\n",
            "Training loss (for one batch) at step 0: 0.0181\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0242\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0209\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0192\n",
            "\n",
            "Start of epoch 12\n",
            "Training loss (for one batch) at step 0: 0.0150\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0147\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0184\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0199\n",
            "\n",
            "Start of epoch 13\n",
            "Training loss (for one batch) at step 0: 0.0200\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0233\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0140\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0167\n",
            "\n",
            "Start of epoch 14\n",
            "Training loss (for one batch) at step 0: 0.0129\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0190\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0183\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0167\n",
            "\n",
            "Start of epoch 15\n",
            "Training loss (for one batch) at step 0: 0.0168\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0126\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0122\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0203\n",
            "\n",
            "Start of epoch 16\n",
            "Training loss (for one batch) at step 0: 0.0148\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0151\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0207\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0168\n",
            "\n",
            "Start of epoch 17\n",
            "Training loss (for one batch) at step 0: 0.0139\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0127\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0109\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0108\n",
            "\n",
            "Start of epoch 18\n",
            "Training loss (for one batch) at step 0: 0.0142\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0137\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0187\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0087\n",
            "\n",
            "Start of epoch 19\n",
            "Training loss (for one batch) at step 0: 0.0177\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0098\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0139\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0095\n",
            "\n",
            "Start of epoch 20\n",
            "Training loss (for one batch) at step 0: 0.0126\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0122\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0132\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0099\n",
            "\n",
            "Start of epoch 21\n",
            "Training loss (for one batch) at step 0: 0.0120\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0146\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0124\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0092\n",
            "\n",
            "Start of epoch 22\n",
            "Training loss (for one batch) at step 0: 0.0100\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0109\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0163\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0140\n",
            "\n",
            "Start of epoch 23\n",
            "Training loss (for one batch) at step 0: 0.0107\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0118\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0087\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0073\n",
            "\n",
            "Start of epoch 24\n",
            "Training loss (for one batch) at step 0: 0.0116\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0120\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0091\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0105\n",
            "\n",
            "Start of epoch 25\n",
            "Training loss (for one batch) at step 0: 0.0107\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0094\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0144\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0099\n",
            "\n",
            "Start of epoch 26\n",
            "Training loss (for one batch) at step 0: 0.0093\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0111\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0138\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0129\n",
            "\n",
            "Start of epoch 27\n",
            "Training loss (for one batch) at step 0: 0.0105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0114\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0115\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0079\n",
            "\n",
            "Start of epoch 28\n",
            "Training loss (for one batch) at step 0: 0.0122\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0097\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0099\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0093\n",
            "\n",
            "Start of epoch 29\n",
            "Training loss (for one batch) at step 0: 0.0123\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0130\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0104\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0114\n",
            "\n",
            "Start of epoch 30\n",
            "Training loss (for one batch) at step 0: 0.0095\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0107\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0085\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0101\n",
            "\n",
            "Start of epoch 31\n",
            "Training loss (for one batch) at step 0: 0.0079\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0070\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0073\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0085\n",
            "\n",
            "Start of epoch 32\n",
            "Training loss (for one batch) at step 0: 0.0119\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0094\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0107\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0075\n",
            "\n",
            "Start of epoch 33\n",
            "Training loss (for one batch) at step 0: 0.0068\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0095\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0091\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0137\n",
            "\n",
            "Start of epoch 34\n",
            "Training loss (for one batch) at step 0: 0.0079\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0107\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0078\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0099\n",
            "\n",
            "Start of epoch 35\n",
            "Training loss (for one batch) at step 0: 0.0069\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0076\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0137\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0089\n",
            "\n",
            "Start of epoch 36\n",
            "Training loss (for one batch) at step 0: 0.0075\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0085\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0076\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0089\n",
            "\n",
            "Start of epoch 37\n",
            "Training loss (for one batch) at step 0: 0.0078\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0082\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0104\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0083\n",
            "\n",
            "Start of epoch 38\n",
            "Training loss (for one batch) at step 0: 0.0075\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0104\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0078\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0081\n",
            "\n",
            "Start of epoch 39\n",
            "Training loss (for one batch) at step 0: 0.0077\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0061\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0090\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0079\n",
            "\n",
            "Start of epoch 40\n",
            "Training loss (for one batch) at step 0: 0.0083\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0093\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0114\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0086\n",
            "\n",
            "Start of epoch 41\n",
            "Training loss (for one batch) at step 0: 0.0097\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0088\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0062\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0062\n",
            "\n",
            "Start of epoch 42\n",
            "Training loss (for one batch) at step 0: 0.0056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0096\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0073\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0082\n",
            "\n",
            "Start of epoch 43\n",
            "Training loss (for one batch) at step 0: 0.0089\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0070\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0079\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0062\n",
            "\n",
            "Start of epoch 44\n",
            "Training loss (for one batch) at step 0: 0.0105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0077\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0069\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0060\n",
            "\n",
            "Start of epoch 45\n",
            "Training loss (for one batch) at step 0: 0.0068\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0093\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0079\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0073\n",
            "\n",
            "Start of epoch 46\n",
            "Training loss (for one batch) at step 0: 0.0063\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0054\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0066\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0086\n",
            "\n",
            "Start of epoch 47\n",
            "Training loss (for one batch) at step 0: 0.0064\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0090\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0072\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0061\n",
            "\n",
            "Start of epoch 48\n",
            "Training loss (for one batch) at step 0: 0.0068\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0064\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0064\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0098\n",
            "\n",
            "Start of epoch 49\n",
            "Training loss (for one batch) at step 0: 0.0106\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0055\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0078\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0063\n",
            "\n",
            "Start of epoch 50\n",
            "Training loss (for one batch) at step 0: 0.0077\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0071\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0068\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0079\n",
            "\n",
            "Start of epoch 51\n",
            "Training loss (for one batch) at step 0: 0.0056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0068\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0098\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0064\n",
            "\n",
            "Start of epoch 52\n",
            "Training loss (for one batch) at step 0: 0.0076\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0086\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0070\n",
            "\n",
            "Start of epoch 53\n",
            "Training loss (for one batch) at step 0: 0.0072\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0063\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0067\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0076\n",
            "\n",
            "Start of epoch 54\n",
            "Training loss (for one batch) at step 0: 0.0067\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0090\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0052\n",
            "\n",
            "Start of epoch 55\n",
            "Training loss (for one batch) at step 0: 0.0053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0064\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0069\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0059\n",
            "\n",
            "Start of epoch 56\n",
            "Training loss (for one batch) at step 0: 0.0070\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0065\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0060\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0069\n",
            "\n",
            "Start of epoch 57\n",
            "Training loss (for one batch) at step 0: 0.0065\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0082\n",
            "\n",
            "Start of epoch 58\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0077\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0056\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0056\n",
            "\n",
            "Start of epoch 59\n",
            "Training loss (for one batch) at step 0: 0.0060\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0074\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0074\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0060\n",
            "\n",
            "Start of epoch 60\n",
            "Training loss (for one batch) at step 0: 0.0072\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0066\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0061\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0055\n",
            "\n",
            "Start of epoch 61\n",
            "Training loss (for one batch) at step 0: 0.0050\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0071\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0057\n",
            "\n",
            "Start of epoch 62\n",
            "Training loss (for one batch) at step 0: 0.0068\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0051\n",
            "\n",
            "Start of epoch 63\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0074\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0056\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0057\n",
            "\n",
            "Start of epoch 64\n",
            "Training loss (for one batch) at step 0: 0.0056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0075\n",
            "\n",
            "Start of epoch 65\n",
            "Training loss (for one batch) at step 0: 0.0049\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0061\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0059\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0088\n",
            "\n",
            "Start of epoch 66\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0091\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0067\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0051\n",
            "\n",
            "Start of epoch 67\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0059\n",
            "\n",
            "Start of epoch 68\n",
            "Training loss (for one batch) at step 0: 0.0056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0065\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0065\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0057\n",
            "\n",
            "Start of epoch 69\n",
            "Training loss (for one batch) at step 0: 0.0085\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0058\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0105\n",
            "\n",
            "Start of epoch 70\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0062\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0048\n",
            "\n",
            "Start of epoch 71\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0055\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0074\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 72\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0054\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0054\n",
            "\n",
            "Start of epoch 73\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0057\n",
            "\n",
            "Start of epoch 74\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 75\n",
            "Training loss (for one batch) at step 0: 0.0060\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0081\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0050\n",
            "\n",
            "Start of epoch 76\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0086\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0038\n",
            "\n",
            "Start of epoch 77\n",
            "Training loss (for one batch) at step 0: 0.0069\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0054\n",
            "\n",
            "Start of epoch 78\n",
            "Training loss (for one batch) at step 0: 0.0046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0071\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0062\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0081\n",
            "\n",
            "Start of epoch 79\n",
            "Training loss (for one batch) at step 0: 0.0060\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0067\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 80\n",
            "Training loss (for one batch) at step 0: 0.0088\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0067\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0054\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0053\n",
            "\n",
            "Start of epoch 81\n",
            "Training loss (for one batch) at step 0: 0.0060\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0060\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0052\n",
            "\n",
            "Start of epoch 82\n",
            "Training loss (for one batch) at step 0: 0.0053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0053\n",
            "\n",
            "Start of epoch 83\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0049\n",
            "\n",
            "Start of epoch 84\n",
            "Training loss (for one batch) at step 0: 0.0062\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 85\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 86\n",
            "Training loss (for one batch) at step 0: 0.0047\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0058\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0047\n",
            "\n",
            "Start of epoch 87\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0049\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0038\n",
            "\n",
            "Start of epoch 88\n",
            "Training loss (for one batch) at step 0: 0.0074\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 89\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0066\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0060\n",
            "\n",
            "Start of epoch 90\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0077\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0057\n",
            "\n",
            "Start of epoch 91\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0063\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0055\n",
            "\n",
            "Start of epoch 92\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 93\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0069\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0075\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0040\n",
            "\n",
            "Start of epoch 94\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0059\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0049\n",
            "\n",
            "Start of epoch 95\n",
            "Training loss (for one batch) at step 0: 0.0089\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 96\n",
            "Training loss (for one batch) at step 0: 0.0053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0065\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 97\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0061\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0051\n",
            "\n",
            "Start of epoch 98\n",
            "Training loss (for one batch) at step 0: 0.0053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0062\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0062\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0061\n",
            "\n",
            "Start of epoch 99\n",
            "Training loss (for one batch) at step 0: 0.0061\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0064\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 100\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 101\n",
            "Training loss (for one batch) at step 0: 0.0055\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 102\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 103\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0041\n",
            "\n",
            "Start of epoch 104\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0052\n",
            "\n",
            "Start of epoch 105\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0068\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0040\n",
            "\n",
            "Start of epoch 106\n",
            "Training loss (for one batch) at step 0: 0.0047\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0059\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 107\n",
            "Training loss (for one batch) at step 0: 0.0046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 108\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0085\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 109\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0065\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 110\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0068\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0047\n",
            "\n",
            "Start of epoch 111\n",
            "Training loss (for one batch) at step 0: 0.0053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0055\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 112\n",
            "Training loss (for one batch) at step 0: 0.0055\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0061\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0038\n",
            "\n",
            "Start of epoch 113\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 114\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 115\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0041\n",
            "\n",
            "Start of epoch 116\n",
            "Training loss (for one batch) at step 0: 0.0063\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0049\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 117\n",
            "Training loss (for one batch) at step 0: 0.0069\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 118\n",
            "Training loss (for one batch) at step 0: 0.0049\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 119\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0063\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0063\n",
            "\n",
            "Start of epoch 120\n",
            "Training loss (for one batch) at step 0: 0.0049\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0063\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 121\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 122\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0059\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0060\n",
            "\n",
            "Start of epoch 123\n",
            "Training loss (for one batch) at step 0: 0.0047\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0060\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0058\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 124\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 125\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 126\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0049\n",
            "\n",
            "Start of epoch 127\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 128\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0052\n",
            "\n",
            "Start of epoch 129\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0096\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0051\n",
            "\n",
            "Start of epoch 130\n",
            "Training loss (for one batch) at step 0: 0.0056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0059\n",
            "\n",
            "Start of epoch 131\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 132\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0050\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0054\n",
            "\n",
            "Start of epoch 133\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0050\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 134\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 135\n",
            "Training loss (for one batch) at step 0: 0.0058\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0050\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 136\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0056\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 137\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 138\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 139\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 140\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0057\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 141\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0055\n",
            "\n",
            "Start of epoch 142\n",
            "Training loss (for one batch) at step 0: 0.0065\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0048\n",
            "\n",
            "Start of epoch 143\n",
            "Training loss (for one batch) at step 0: 0.0069\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0082\n",
            "\n",
            "Start of epoch 144\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 145\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0067\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0062\n",
            "\n",
            "Start of epoch 146\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0062\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0058\n",
            "\n",
            "Start of epoch 147\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0040\n",
            "\n",
            "Start of epoch 148\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 149\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 150\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 151\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 152\n",
            "Training loss (for one batch) at step 0: 0.0049\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 153\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0058\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 154\n",
            "Training loss (for one batch) at step 0: 0.0069\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 155\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 156\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 157\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0060\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 158\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 159\n",
            "Training loss (for one batch) at step 0: 0.0061\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 160\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 161\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0058\n",
            "\n",
            "Start of epoch 162\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 163\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0056\n",
            "\n",
            "Start of epoch 164\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 165\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0055\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 166\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 167\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 168\n",
            "Training loss (for one batch) at step 0: 0.0047\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0047\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 169\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 170\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 171\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 172\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0041\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 173\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 174\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 175\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 176\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0050\n",
            "\n",
            "Start of epoch 177\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0062\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0056\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 178\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 179\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 180\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0062\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 181\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0071\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0066\n",
            "\n",
            "Start of epoch 182\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0038\n",
            "\n",
            "Start of epoch 183\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 184\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0053\n",
            "\n",
            "Start of epoch 185\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 186\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0058\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 187\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 188\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0055\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 189\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 190\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0054\n",
            "\n",
            "Start of epoch 191\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 192\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0054\n",
            "\n",
            "Start of epoch 193\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 194\n",
            "Training loss (for one batch) at step 0: 0.0057\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 195\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0065\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0049\n",
            "\n",
            "Start of epoch 196\n",
            "Training loss (for one batch) at step 0: 0.0058\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0061\n",
            "\n",
            "Start of epoch 197\n",
            "Training loss (for one batch) at step 0: 0.0053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0050\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 198\n",
            "Training loss (for one batch) at step 0: 0.0046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 199\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0072\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0051\n",
            "\n",
            "Start of epoch 200\n",
            "Training loss (for one batch) at step 0: 0.0055\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 201\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 202\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 203\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 204\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0058\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 205\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 206\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0054\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0051\n",
            "\n",
            "Start of epoch 207\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 208\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 209\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 210\n",
            "Training loss (for one batch) at step 0: 0.0061\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 211\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0058\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 212\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 213\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 214\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 215\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0054\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 216\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0059\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 217\n",
            "Training loss (for one batch) at step 0: 0.0056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 218\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0049\n",
            "\n",
            "Start of epoch 219\n",
            "Training loss (for one batch) at step 0: 0.0067\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 220\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 221\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0018\n",
            "\n",
            "Start of epoch 222\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 223\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 224\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 225\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 226\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 227\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0052\n",
            "\n",
            "Start of epoch 228\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0059\n",
            "\n",
            "Start of epoch 229\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 230\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 231\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0060\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 232\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0053\n",
            "\n",
            "Start of epoch 233\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 234\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0041\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0053\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 235\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 236\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 237\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 238\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 239\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 240\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0047\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 241\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 242\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 243\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 244\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 245\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 246\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 247\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 248\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 249\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0041\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 250\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 251\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0049\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 252\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 253\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 254\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0048\n",
            "\n",
            "Start of epoch 255\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 256\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 257\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 258\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 259\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0038\n",
            "\n",
            "Start of epoch 260\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 261\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0050\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0040\n",
            "\n",
            "Start of epoch 262\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 263\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 264\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 265\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 266\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 267\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0052\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0061\n",
            "\n",
            "Start of epoch 268\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 269\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 270\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 271\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 272\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 273\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0055\n",
            "\n",
            "Start of epoch 274\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0064\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 275\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 276\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 277\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0018\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 278\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 279\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0041\n",
            "\n",
            "Start of epoch 280\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0055\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 281\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 282\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 283\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 284\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 285\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 286\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 287\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0041\n",
            "\n",
            "Start of epoch 288\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 289\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0023\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 290\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 291\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 292\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 293\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0048\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0041\n",
            "\n",
            "Start of epoch 294\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 295\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 296\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0048\n",
            "\n",
            "Start of epoch 297\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 298\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 299\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0047\n",
            "\n",
            "Start of epoch 300\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 301\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 302\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 303\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 304\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 305\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0066\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 306\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 307\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0023\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 308\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 309\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 310\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 311\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 312\n",
            "Training loss (for one batch) at step 0: 0.0050\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 313\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 314\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 315\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 316\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0041\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 317\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0046\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 318\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0041\n",
            "\n",
            "Start of epoch 319\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 320\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 321\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 322\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 323\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 324\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 325\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 326\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 327\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 328\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 329\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 330\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0019\n",
            "\n",
            "Start of epoch 331\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 332\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0049\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 333\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 334\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 335\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0060\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 336\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 337\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 338\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0039\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 339\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 340\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 341\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 342\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 343\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 344\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 345\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 346\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 347\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 348\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0040\n",
            "\n",
            "Start of epoch 349\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0058\n",
            "\n",
            "Start of epoch 350\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 351\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 352\n",
            "Training loss (for one batch) at step 0: 0.0047\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 353\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 354\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 355\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 356\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 357\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 358\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 359\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 360\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 361\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 362\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 363\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 364\n",
            "Training loss (for one batch) at step 0: 0.0057\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0049\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 365\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0045\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 366\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 367\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 368\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0023\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0048\n",
            "\n",
            "Start of epoch 369\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 370\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0021\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 371\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 372\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0055\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 373\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 374\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 375\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 376\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 377\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 378\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 379\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 380\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 381\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 382\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 383\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 384\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 385\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 386\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 387\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 388\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 389\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0055\n",
            "\n",
            "Start of epoch 390\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 391\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 392\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 393\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 394\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 395\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 396\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 397\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 398\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 399\n",
            "Training loss (for one batch) at step 0: 0.0046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 400\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0037\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0074\n",
            "\n",
            "Start of epoch 401\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 402\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 403\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 404\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 405\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 406\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 407\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 408\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 409\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0031\n",
            "\n",
            "Start of epoch 410\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 411\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0051\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 412\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 413\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 414\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 415\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0050\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 416\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 417\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 418\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 419\n",
            "Training loss (for one batch) at step 0: 0.0055\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0037\n",
            "\n",
            "Start of epoch 420\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 421\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 422\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 423\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 424\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 425\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 426\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 427\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0053\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 428\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0055\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 429\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 430\n",
            "Training loss (for one batch) at step 0: 0.0046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0048\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 431\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 432\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 433\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 434\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 435\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 436\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 437\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0020\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 438\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 439\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0045\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 440\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0036\n",
            "\n",
            "Start of epoch 441\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 442\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 443\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 444\n",
            "Training loss (for one batch) at step 0: 0.0057\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 445\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0023\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 446\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0019\n",
            "\n",
            "Start of epoch 447\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 448\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0029\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 449\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 450\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 451\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 452\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0019\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0035\n",
            "\n",
            "Start of epoch 453\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 454\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0045\n",
            "\n",
            "Start of epoch 455\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 456\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 457\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 458\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 459\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0022\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 460\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0034\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0039\n",
            "\n",
            "Start of epoch 461\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0024\n",
            "\n",
            "Start of epoch 462\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 463\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 464\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 465\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0023\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 466\n",
            "Training loss (for one batch) at step 0: 0.0054\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 467\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 468\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0021\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0023\n",
            "\n",
            "Start of epoch 469\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 470\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0041\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0044\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 471\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0030\n",
            "\n",
            "Start of epoch 472\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 473\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 474\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0032\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 475\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0037\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 476\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0041\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 477\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0047\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0025\n",
            "\n",
            "Start of epoch 478\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0054\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n",
            "\n",
            "Start of epoch 479\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0044\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0042\n",
            "\n",
            "Start of epoch 480\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0046\n",
            "\n",
            "Start of epoch 481\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 482\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0053\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0026\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0044\n",
            "\n",
            "Start of epoch 483\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0052\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0032\n",
            "\n",
            "Start of epoch 484\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0046\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0022\n",
            "\n",
            "Start of epoch 485\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0040\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0033\n",
            "\n",
            "Start of epoch 486\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0021\n",
            "\n",
            "Start of epoch 487\n",
            "Training loss (for one batch) at step 0: 0.0035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0034\n",
            "\n",
            "Start of epoch 488\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0043\n",
            "\n",
            "Start of epoch 489\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 490\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 491\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0032\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 492\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0021\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0035\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 493\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0028\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0020\n",
            "\n",
            "Start of epoch 494\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0027\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 495\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0040\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0026\n",
            "\n",
            "Start of epoch 496\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0038\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0028\n",
            "\n",
            "Start of epoch 497\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0043\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 498\n",
            "Training loss (for one batch) at step 0: 0.0043\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0036\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0033\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0027\n",
            "\n",
            "Start of epoch 499\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.0026\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.0030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.0029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYc1EE-yrmVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c837d657-ae29-40d2-f800-382fe13b746e"
      },
      "source": [
        "prediction = model.predict(X_test)\n",
        "f1, f2, f3 = prediction.T\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(f1, f2, f3, 'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fe1225b29b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZAks17s1Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use Lecture's"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}