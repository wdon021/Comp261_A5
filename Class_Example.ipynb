{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmnrQDE6RfUoZ27iQbmigP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdon021/Comp261_A5/blob/master/Class_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-bkKamI1UeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tro7iEX-ew8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = [0, 0, 0]\n",
        "cov = [[1, 0, 0],\n",
        "       [0, 1, 0],\n",
        "       [0, 0, 1]]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b135hxdIfNxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unit_sphere(data):\n",
        "  return np.array([[coord / math.sqrt(sum(coords * coords for coords in line)) for coord in line] for line in data])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTrKt37dfPnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "united = np.random.multivariate_normal(mean, cov, 4000)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObgwOT9zfTjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x11, x22, x33 = united.T\n",
        "united_y = unit_sphere(united)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEqaNvahfVfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "46fe8530-8400-4862-c533-5d92232e9f7b"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(x11, x22, x33, 'o')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fdaefa3f208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PmRxaopfXGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(united, united_y, test_size = 0.25)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4uQtuxLfcLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.25)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stLTEF21nI8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5915ee93-636e-4e63-dd81-5882768899ae"
      },
      "source": [
        "x11, x22, x33 = Y_test.T\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(x11, x22, x33, 'o')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fdaa67c24a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6FVQAflffQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ba4d273-b3b1-4bc9-b9a5-995ac883146a"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow import keras\n",
        "import keras.backend as kb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kacclnf9fglJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = keras.Input(shape = (3,))\n",
        "x1 = layers.Dense(10, activation=\"relu\")(inputs)\n",
        "x2 = layers.Dense(10, activation='relu')(x1)\n",
        "outputs = layers.Dense(3, activation='linear')(x2)\n",
        "model = keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1misytrfmUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate an optimizer\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6XLrbgufomH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training dataset\n",
        "batch_size = 100"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt-4C5xIfpRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tf.cast(X_train, tf.float32)\n",
        "Y_train = tf.cast(Y_train, tf.float32)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBaHU1stfuGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = tf.cast(X_val, tf.float32)\n",
        "Y_val = tf.cast(Y_val, tf.float32)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPD_YTIzfrU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tf.cast(X_test, tf.float32)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--05jxiSf12q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creates a dataset with a separate element fro each row of the input tensor\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(buffer_size= 3000).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).shuffle(1000).batch(batch_size)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cNuUWdXgG8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "epochs = 500"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9M4pfzBg_Pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an loss function # not effective\n",
        "def Keras_loss_function(y_actual, y_predicted):\n",
        "  mse = kb.mean(kb.sum(kb.square(y_actual - y_predicted))) # (1/n*(sum(sqr(Y-Y_hat))))\n",
        "  return mse\n",
        "\n",
        "# first 100 epochs is useful"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UCU9yX8gL0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ddf8e62-5c28-4a22-ce48-a5d77ec84b04"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "    # open a GradientTape to record the operations run during the feed forward\n",
        "    # enables aoto-partial-Differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "      # run the feed foward process of the layers.\n",
        "      # the operations that the layers apply to its inpurts and going to bee recorded on the GradientTape\n",
        "      linear = model(x_batch_train, training = True)\n",
        "      # print(linear)\n",
        "      # compute the loss value for this minibatch\n",
        "      mse = Keras_loss_function(y_batch_train, linear)\n",
        "      # mse = tf.keras.losses.MSE(y_batch_train, linear)\n",
        "      # print(mse)\n",
        "      # mse = keras.losses.mean_squared_error(y_batch_train, linear) # mse gives 3 number\n",
        "    # print(mse)\n",
        "    # use the gradient tap to automatically retrieve the gradients of the \n",
        "    # trainable variables with respect to the loss\n",
        "    grads = tape.gradient(mse, model.trainable_weights)\n",
        "    # print(grads)\n",
        "    # weight + bias for every layer\n",
        "    # run one step of gradient dscent by updating the value of the variables to minize the loss\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    # print(model.trainable_weights,'\\n')\n",
        "    # print log information every 10 batches.\n",
        "    if step % 10 == 0:\n",
        "      print(\n",
        "          \"Training loss (for one batch) at step %d: %.4f\"\n",
        "          %(step, float(mse))\n",
        "      )\n",
        "      print(\"seen so far: %s samples\" % ((step +1) * 100))\n",
        "\n",
        "\n",
        "  # Run a validation loop at the end of each epoch\n",
        "  for x_batch_val, y_batch_val in val_dataset:\n",
        "    val_linear = model(x_batch_val, training = False)\n",
        "    val_mse = Keras_loss_function(y_batch_val, val_linear)\n",
        "\n",
        "  # print MSE for validation set\n",
        "  print(\"validation MSE: %.4f\" % (float(val_mse)))\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 161.4005\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 147.6059\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 137.6904\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 58.1657\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 120.0262\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 117.2203\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 104.5565\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 49.0517\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 95.2784\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 87.5972\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 79.9248\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 37.1034\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 79.6720\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 70.6396\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 64.2727\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 33.4465\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 63.4362\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 62.3900\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 53.8432\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 28.8013\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 57.6579\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 44.4591\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 42.6775\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 20.9858\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 39.9979\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 41.8617\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 36.7153\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 15.3387\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 30.5219\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 30.8408\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 26.2918\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 13.7357\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 30.2422\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 24.4422\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 22.3499\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 10.1965\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 22.9489\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 18.6880\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 17.2945\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 7.4732\n",
            "\n",
            "Start of epoch 10\n",
            "Training loss (for one batch) at step 0: 15.9625\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 16.5612\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 12.4640\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 6.6211\n",
            "\n",
            "Start of epoch 11\n",
            "Training loss (for one batch) at step 0: 14.5706\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 12.1288\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 12.9339\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.6841\n",
            "\n",
            "Start of epoch 12\n",
            "Training loss (for one batch) at step 0: 14.6339\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 11.8489\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 10.4062\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.9855\n",
            "\n",
            "Start of epoch 13\n",
            "Training loss (for one batch) at step 0: 10.0062\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 11.2406\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 9.8656\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 5.5439\n",
            "\n",
            "Start of epoch 14\n",
            "Training loss (for one batch) at step 0: 11.7557\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 9.1354\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 10.0619\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.3575\n",
            "\n",
            "Start of epoch 15\n",
            "Training loss (for one batch) at step 0: 10.9192\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 10.0775\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 8.3272\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 7.4379\n",
            "\n",
            "Start of epoch 16\n",
            "Training loss (for one batch) at step 0: 9.2606\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 7.1842\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 10.3609\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.8895\n",
            "\n",
            "Start of epoch 17\n",
            "Training loss (for one batch) at step 0: 8.9730\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.9031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.1273\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.1364\n",
            "\n",
            "Start of epoch 18\n",
            "Training loss (for one batch) at step 0: 6.7487\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.2961\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.5687\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.3266\n",
            "\n",
            "Start of epoch 19\n",
            "Training loss (for one batch) at step 0: 7.9723\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 7.7419\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 8.4609\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.9592\n",
            "\n",
            "Start of epoch 20\n",
            "Training loss (for one batch) at step 0: 6.9390\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 8.5832\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.9196\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 4.2151\n",
            "\n",
            "Start of epoch 21\n",
            "Training loss (for one batch) at step 0: 8.3061\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 7.8629\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.9617\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.6981\n",
            "\n",
            "Start of epoch 22\n",
            "Training loss (for one batch) at step 0: 8.4706\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.1370\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 7.2550\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.0965\n",
            "\n",
            "Start of epoch 23\n",
            "Training loss (for one batch) at step 0: 6.9504\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.8260\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.3372\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.9809\n",
            "\n",
            "Start of epoch 24\n",
            "Training loss (for one batch) at step 0: 5.9817\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 7.1455\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.8666\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.9382\n",
            "\n",
            "Start of epoch 25\n",
            "Training loss (for one batch) at step 0: 6.4239\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 6.1291\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.5271\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.9455\n",
            "\n",
            "Start of epoch 26\n",
            "Training loss (for one batch) at step 0: 6.6714\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.4135\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.0965\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.1333\n",
            "\n",
            "Start of epoch 27\n",
            "Training loss (for one batch) at step 0: 8.5832\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.0511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.8042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.9451\n",
            "\n",
            "Start of epoch 28\n",
            "Training loss (for one batch) at step 0: 5.8039\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.3209\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.7682\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.9315\n",
            "\n",
            "Start of epoch 29\n",
            "Training loss (for one batch) at step 0: 5.9864\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.2103\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.2727\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.0019\n",
            "\n",
            "Start of epoch 30\n",
            "Training loss (for one batch) at step 0: 5.0548\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.5250\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.6478\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8881\n",
            "\n",
            "Start of epoch 31\n",
            "Training loss (for one batch) at step 0: 6.3607\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.4465\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.3335\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.3976\n",
            "\n",
            "Start of epoch 32\n",
            "Training loss (for one batch) at step 0: 5.4797\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.1126\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.6231\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.0937\n",
            "\n",
            "Start of epoch 33\n",
            "Training loss (for one batch) at step 0: 5.4853\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.8223\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 5.8291\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.3813\n",
            "\n",
            "Start of epoch 34\n",
            "Training loss (for one batch) at step 0: 4.8349\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 5.6266\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.5216\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.3329\n",
            "\n",
            "Start of epoch 35\n",
            "Training loss (for one batch) at step 0: 5.9206\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.3111\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.3586\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.1555\n",
            "\n",
            "Start of epoch 36\n",
            "Training loss (for one batch) at step 0: 6.1300\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.3937\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.3623\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 3.1308\n",
            "\n",
            "Start of epoch 37\n",
            "Training loss (for one batch) at step 0: 5.6769\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.3645\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.6614\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.3299\n",
            "\n",
            "Start of epoch 38\n",
            "Training loss (for one batch) at step 0: 4.5351\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.8096\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.9980\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.0442\n",
            "\n",
            "Start of epoch 39\n",
            "Training loss (for one batch) at step 0: 5.0252\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.6148\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 6.4934\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.6997\n",
            "\n",
            "Start of epoch 40\n",
            "Training loss (for one batch) at step 0: 4.5830\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.3361\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.0236\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.4017\n",
            "\n",
            "Start of epoch 41\n",
            "Training loss (for one batch) at step 0: 5.4540\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.1556\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.7203\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5791\n",
            "\n",
            "Start of epoch 42\n",
            "Training loss (for one batch) at step 0: 4.7401\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.3058\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4485\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.1128\n",
            "\n",
            "Start of epoch 43\n",
            "Training loss (for one batch) at step 0: 3.5598\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.9240\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.9539\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8893\n",
            "\n",
            "Start of epoch 44\n",
            "Training loss (for one batch) at step 0: 4.3813\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.9342\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.9947\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.1818\n",
            "\n",
            "Start of epoch 45\n",
            "Training loss (for one batch) at step 0: 4.5287\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.6597\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4426\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8483\n",
            "\n",
            "Start of epoch 46\n",
            "Training loss (for one batch) at step 0: 5.1917\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4089\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.2259\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.1631\n",
            "\n",
            "Start of epoch 47\n",
            "Training loss (for one batch) at step 0: 3.7250\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.6367\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.0000\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.5545\n",
            "\n",
            "Start of epoch 48\n",
            "Training loss (for one batch) at step 0: 4.7059\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.9614\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.2236\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.6832\n",
            "\n",
            "Start of epoch 49\n",
            "Training loss (for one batch) at step 0: 3.0964\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1740\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.5082\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.6696\n",
            "\n",
            "Start of epoch 50\n",
            "Training loss (for one batch) at step 0: 4.0435\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.6406\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4092\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4593\n",
            "\n",
            "Start of epoch 51\n",
            "Training loss (for one batch) at step 0: 3.1931\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.2903\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.7256\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6036\n",
            "\n",
            "Start of epoch 52\n",
            "Training loss (for one batch) at step 0: 4.6940\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.6163\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.6057\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9271\n",
            "\n",
            "Start of epoch 53\n",
            "Training loss (for one batch) at step 0: 3.2313\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8138\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 4.0431\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6836\n",
            "\n",
            "Start of epoch 54\n",
            "Training loss (for one batch) at step 0: 2.8758\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.1996\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.0268\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4621\n",
            "\n",
            "Start of epoch 55\n",
            "Training loss (for one batch) at step 0: 3.6751\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.8736\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4258\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2221\n",
            "\n",
            "Start of epoch 56\n",
            "Training loss (for one batch) at step 0: 3.0680\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9169\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.3309\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5673\n",
            "\n",
            "Start of epoch 57\n",
            "Training loss (for one batch) at step 0: 2.7438\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.3628\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4544\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4664\n",
            "\n",
            "Start of epoch 58\n",
            "Training loss (for one batch) at step 0: 3.4573\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.6859\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9818\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.0119\n",
            "\n",
            "Start of epoch 59\n",
            "Training loss (for one batch) at step 0: 3.9461\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6269\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4193\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8424\n",
            "\n",
            "Start of epoch 60\n",
            "Training loss (for one batch) at step 0: 2.8683\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1723\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.3538\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.2304\n",
            "\n",
            "Start of epoch 61\n",
            "Training loss (for one batch) at step 0: 3.5622\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.7039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.0905\n",
            "\n",
            "Start of epoch 62\n",
            "Training loss (for one batch) at step 0: 2.9276\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.0941\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.1288\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9646\n",
            "\n",
            "Start of epoch 63\n",
            "Training loss (for one batch) at step 0: 2.6209\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.7903\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4926\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.2800\n",
            "\n",
            "Start of epoch 64\n",
            "Training loss (for one batch) at step 0: 3.8605\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.5895\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4741\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.7785\n",
            "\n",
            "Start of epoch 65\n",
            "Training loss (for one batch) at step 0: 3.0242\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.6027\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9253\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2571\n",
            "\n",
            "Start of epoch 66\n",
            "Training loss (for one batch) at step 0: 3.1141\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3944\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.1803\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.0197\n",
            "\n",
            "Start of epoch 67\n",
            "Training loss (for one batch) at step 0: 2.8410\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9430\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9759\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5403\n",
            "\n",
            "Start of epoch 68\n",
            "Training loss (for one batch) at step 0: 3.0726\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7035\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.5890\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.3464\n",
            "\n",
            "Start of epoch 69\n",
            "Training loss (for one batch) at step 0: 3.3589\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1289\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7489\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0643\n",
            "\n",
            "Start of epoch 70\n",
            "Training loss (for one batch) at step 0: 2.8664\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 4.2929\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7890\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.1638\n",
            "\n",
            "Start of epoch 71\n",
            "Training loss (for one batch) at step 0: 2.5620\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7403\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.3094\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2305\n",
            "\n",
            "Start of epoch 72\n",
            "Training loss (for one batch) at step 0: 2.5207\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6283\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9305\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.7219\n",
            "\n",
            "Start of epoch 73\n",
            "Training loss (for one batch) at step 0: 3.2698\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5613\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.0439\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.7442\n",
            "\n",
            "Start of epoch 74\n",
            "Training loss (for one batch) at step 0: 2.2441\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6619\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0443\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1322\n",
            "\n",
            "Start of epoch 75\n",
            "Training loss (for one batch) at step 0: 2.4507\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.4444\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3147\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.8361\n",
            "\n",
            "Start of epoch 76\n",
            "Training loss (for one batch) at step 0: 2.3897\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.3674\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.5445\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6227\n",
            "\n",
            "Start of epoch 77\n",
            "Training loss (for one batch) at step 0: 2.1708\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8098\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1817\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 2.1695\n",
            "\n",
            "Start of epoch 78\n",
            "Training loss (for one batch) at step 0: 3.0982\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.7786\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3401\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1979\n",
            "\n",
            "Start of epoch 79\n",
            "Training loss (for one batch) at step 0: 2.9169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9654\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.9181\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5812\n",
            "\n",
            "Start of epoch 80\n",
            "Training loss (for one batch) at step 0: 2.5255\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3228\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2280\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0088\n",
            "\n",
            "Start of epoch 81\n",
            "Training loss (for one batch) at step 0: 2.6575\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9927\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7589\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0442\n",
            "\n",
            "Start of epoch 82\n",
            "Training loss (for one batch) at step 0: 3.5510\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4712\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3000\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9910\n",
            "\n",
            "Start of epoch 83\n",
            "Training loss (for one batch) at step 0: 2.2460\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6399\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5630\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5014\n",
            "\n",
            "Start of epoch 84\n",
            "Training loss (for one batch) at step 0: 2.6309\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6540\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3569\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0785\n",
            "\n",
            "Start of epoch 85\n",
            "Training loss (for one batch) at step 0: 2.0259\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4197\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0923\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8822\n",
            "\n",
            "Start of epoch 86\n",
            "Training loss (for one batch) at step 0: 2.2104\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3580\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9857\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5740\n",
            "\n",
            "Start of epoch 87\n",
            "Training loss (for one batch) at step 0: 2.1709\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1688\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6821\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4141\n",
            "\n",
            "Start of epoch 88\n",
            "Training loss (for one batch) at step 0: 1.9257\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.1702\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6543\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0796\n",
            "\n",
            "Start of epoch 89\n",
            "Training loss (for one batch) at step 0: 2.1333\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3025\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.8367\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1648\n",
            "\n",
            "Start of epoch 90\n",
            "Training loss (for one batch) at step 0: 2.0139\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5765\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7031\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4796\n",
            "\n",
            "Start of epoch 91\n",
            "Training loss (for one batch) at step 0: 2.8871\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5762\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7302\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9554\n",
            "\n",
            "Start of epoch 92\n",
            "Training loss (for one batch) at step 0: 1.9396\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2297\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6002\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1053\n",
            "\n",
            "Start of epoch 93\n",
            "Training loss (for one batch) at step 0: 1.8817\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1344\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.2133\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.9579\n",
            "\n",
            "Start of epoch 94\n",
            "Training loss (for one batch) at step 0: 2.2038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2833\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0275\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8422\n",
            "\n",
            "Start of epoch 95\n",
            "Training loss (for one batch) at step 0: 1.9234\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8422\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7894\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1764\n",
            "\n",
            "Start of epoch 96\n",
            "Training loss (for one batch) at step 0: 1.9614\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6975\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0166\n",
            "\n",
            "Start of epoch 97\n",
            "Training loss (for one batch) at step 0: 3.0127\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6297\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.4336\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0470\n",
            "\n",
            "Start of epoch 98\n",
            "Training loss (for one batch) at step 0: 1.9880\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3899\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9978\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8056\n",
            "\n",
            "Start of epoch 99\n",
            "Training loss (for one batch) at step 0: 2.8859\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.2984\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6247\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7205\n",
            "\n",
            "Start of epoch 100\n",
            "Training loss (for one batch) at step 0: 2.0890\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2611\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8366\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7854\n",
            "\n",
            "Start of epoch 101\n",
            "Training loss (for one batch) at step 0: 2.1319\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9132\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3305\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4953\n",
            "\n",
            "Start of epoch 102\n",
            "Training loss (for one batch) at step 0: 2.0046\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2316\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.5878\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9412\n",
            "\n",
            "Start of epoch 103\n",
            "Training loss (for one batch) at step 0: 2.2152\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6724\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7925\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0498\n",
            "\n",
            "Start of epoch 104\n",
            "Training loss (for one batch) at step 0: 1.8064\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7180\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9688\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5222\n",
            "\n",
            "Start of epoch 105\n",
            "Training loss (for one batch) at step 0: 2.0685\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.5401\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5102\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9693\n",
            "\n",
            "Start of epoch 106\n",
            "Training loss (for one batch) at step 0: 1.9050\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4961\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9055\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6831\n",
            "\n",
            "Start of epoch 107\n",
            "Training loss (for one batch) at step 0: 2.4128\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4879\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.8362\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7396\n",
            "\n",
            "Start of epoch 108\n",
            "Training loss (for one batch) at step 0: 1.7929\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4333\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1480\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2103\n",
            "\n",
            "Start of epoch 109\n",
            "Training loss (for one batch) at step 0: 1.7326\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0308\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3413\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8071\n",
            "\n",
            "Start of epoch 110\n",
            "Training loss (for one batch) at step 0: 1.3639\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2224\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1343\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5592\n",
            "\n",
            "Start of epoch 111\n",
            "Training loss (for one batch) at step 0: 1.9410\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6514\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4109\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8256\n",
            "\n",
            "Start of epoch 112\n",
            "Training loss (for one batch) at step 0: 2.3453\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6280\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.8573\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1556\n",
            "\n",
            "Start of epoch 113\n",
            "Training loss (for one batch) at step 0: 1.8310\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6247\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.7694\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4016\n",
            "\n",
            "Start of epoch 114\n",
            "Training loss (for one batch) at step 0: 2.1006\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2877\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9786\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1502\n",
            "\n",
            "Start of epoch 115\n",
            "Training loss (for one batch) at step 0: 1.6588\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8841\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.4592\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2881\n",
            "\n",
            "Start of epoch 116\n",
            "Training loss (for one batch) at step 0: 3.4464\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.9004\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8177\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0800\n",
            "\n",
            "Start of epoch 117\n",
            "Training loss (for one batch) at step 0: 2.1663\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7166\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9593\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7827\n",
            "\n",
            "Start of epoch 118\n",
            "Training loss (for one batch) at step 0: 2.1488\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.8269\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5254\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3995\n",
            "\n",
            "Start of epoch 119\n",
            "Training loss (for one batch) at step 0: 1.5045\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0306\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3495\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0403\n",
            "\n",
            "Start of epoch 120\n",
            "Training loss (for one batch) at step 0: 1.6905\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8131\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.6350\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8351\n",
            "\n",
            "Start of epoch 121\n",
            "Training loss (for one batch) at step 0: 1.9286\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.6336\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.2042\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6534\n",
            "\n",
            "Start of epoch 122\n",
            "Training loss (for one batch) at step 0: 1.9398\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6130\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0226\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8153\n",
            "\n",
            "Start of epoch 123\n",
            "Training loss (for one batch) at step 0: 1.8303\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4915\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5235\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7792\n",
            "\n",
            "Start of epoch 124\n",
            "Training loss (for one batch) at step 0: 2.2011\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5909\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5401\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6716\n",
            "\n",
            "Start of epoch 125\n",
            "Training loss (for one batch) at step 0: 1.8069\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7832\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9743\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7946\n",
            "\n",
            "Start of epoch 126\n",
            "Training loss (for one batch) at step 0: 1.9476\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8533\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0338\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0166\n",
            "\n",
            "Start of epoch 127\n",
            "Training loss (for one batch) at step 0: 1.5204\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2114\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8328\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8898\n",
            "\n",
            "Start of epoch 128\n",
            "Training loss (for one batch) at step 0: 1.6748\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5077\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3706\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7607\n",
            "\n",
            "Start of epoch 129\n",
            "Training loss (for one batch) at step 0: 1.5120\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9832\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9976\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7708\n",
            "\n",
            "Start of epoch 130\n",
            "Training loss (for one batch) at step 0: 1.7985\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4874\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5076\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7573\n",
            "\n",
            "Start of epoch 131\n",
            "Training loss (for one batch) at step 0: 1.8226\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6452\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1190\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0087\n",
            "\n",
            "Start of epoch 132\n",
            "Training loss (for one batch) at step 0: 2.0092\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4777\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6616\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1827\n",
            "\n",
            "Start of epoch 133\n",
            "Training loss (for one batch) at step 0: 2.2702\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9737\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5372\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0941\n",
            "\n",
            "Start of epoch 134\n",
            "Training loss (for one batch) at step 0: 1.9282\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6285\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 3.2200\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8169\n",
            "\n",
            "Start of epoch 135\n",
            "Training loss (for one batch) at step 0: 2.0751\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4268\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3448\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7912\n",
            "\n",
            "Start of epoch 136\n",
            "Training loss (for one batch) at step 0: 1.4561\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4030\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7289\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6456\n",
            "\n",
            "Start of epoch 137\n",
            "Training loss (for one batch) at step 0: 1.4184\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6066\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7268\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.5513\n",
            "\n",
            "Start of epoch 138\n",
            "Training loss (for one batch) at step 0: 1.6622\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6152\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0724\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1067\n",
            "\n",
            "Start of epoch 139\n",
            "Training loss (for one batch) at step 0: 1.5167\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7115\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7065\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7297\n",
            "\n",
            "Start of epoch 140\n",
            "Training loss (for one batch) at step 0: 1.7559\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1615\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7153\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9518\n",
            "\n",
            "Start of epoch 141\n",
            "Training loss (for one batch) at step 0: 1.4967\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.4839\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7691\n",
            "\n",
            "Start of epoch 142\n",
            "Training loss (for one batch) at step 0: 1.2859\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8825\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8854\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9788\n",
            "\n",
            "Start of epoch 143\n",
            "Training loss (for one batch) at step 0: 2.0166\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6967\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8762\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0649\n",
            "\n",
            "Start of epoch 144\n",
            "Training loss (for one batch) at step 0: 1.4295\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9903\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2370\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8335\n",
            "\n",
            "Start of epoch 145\n",
            "Training loss (for one batch) at step 0: 1.2711\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9570\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6061\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.2820\n",
            "\n",
            "Start of epoch 146\n",
            "Training loss (for one batch) at step 0: 1.8889\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6406\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8636\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9652\n",
            "\n",
            "Start of epoch 147\n",
            "Training loss (for one batch) at step 0: 1.6557\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7957\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7241\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5703\n",
            "\n",
            "Start of epoch 148\n",
            "Training loss (for one batch) at step 0: 1.5615\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5012\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5215\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8248\n",
            "\n",
            "Start of epoch 149\n",
            "Training loss (for one batch) at step 0: 1.0664\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8147\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5908\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8394\n",
            "\n",
            "Start of epoch 150\n",
            "Training loss (for one batch) at step 0: 2.0575\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5771\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6822\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7167\n",
            "\n",
            "Start of epoch 151\n",
            "Training loss (for one batch) at step 0: 1.6212\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6224\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6632\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3384\n",
            "\n",
            "Start of epoch 152\n",
            "Training loss (for one batch) at step 0: 1.9661\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2233\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5020\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8555\n",
            "\n",
            "Start of epoch 153\n",
            "Training loss (for one batch) at step 0: 1.2540\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9951\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1981\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8765\n",
            "\n",
            "Start of epoch 154\n",
            "Training loss (for one batch) at step 0: 1.7372\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5641\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9478\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7560\n",
            "\n",
            "Start of epoch 155\n",
            "Training loss (for one batch) at step 0: 1.7874\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1889\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8942\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.4667\n",
            "\n",
            "Start of epoch 156\n",
            "Training loss (for one batch) at step 0: 1.3985\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3562\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7692\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7454\n",
            "\n",
            "Start of epoch 157\n",
            "Training loss (for one batch) at step 0: 1.6663\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5330\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8290\n",
            "\n",
            "Start of epoch 158\n",
            "Training loss (for one batch) at step 0: 1.7429\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 3.5135\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8410\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7023\n",
            "\n",
            "Start of epoch 159\n",
            "Training loss (for one batch) at step 0: 1.6197\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3396\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3250\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5261\n",
            "\n",
            "Start of epoch 160\n",
            "Training loss (for one batch) at step 0: 1.3233\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4585\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3111\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1113\n",
            "\n",
            "Start of epoch 161\n",
            "Training loss (for one batch) at step 0: 2.2184\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5321\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.1886\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7215\n",
            "\n",
            "Start of epoch 162\n",
            "Training loss (for one batch) at step 0: 1.2845\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7087\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0373\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7035\n",
            "\n",
            "Start of epoch 163\n",
            "Training loss (for one batch) at step 0: 2.0563\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3524\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6467\n",
            "\n",
            "Start of epoch 164\n",
            "Training loss (for one batch) at step 0: 1.8244\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6424\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4358\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6013\n",
            "\n",
            "Start of epoch 165\n",
            "Training loss (for one batch) at step 0: 1.8339\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5021\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1949\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3530\n",
            "\n",
            "Start of epoch 166\n",
            "Training loss (for one batch) at step 0: 1.3296\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2179\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5686\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1807\n",
            "\n",
            "Start of epoch 167\n",
            "Training loss (for one batch) at step 0: 1.6424\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2869\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4166\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5090\n",
            "\n",
            "Start of epoch 168\n",
            "Training loss (for one batch) at step 0: 1.4427\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3698\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6111\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8447\n",
            "\n",
            "Start of epoch 169\n",
            "Training loss (for one batch) at step 0: 1.0169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4185\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4977\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8508\n",
            "\n",
            "Start of epoch 170\n",
            "Training loss (for one batch) at step 0: 2.1959\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0691\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2602\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1318\n",
            "\n",
            "Start of epoch 171\n",
            "Training loss (for one batch) at step 0: 1.3798\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0636\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6888\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6035\n",
            "\n",
            "Start of epoch 172\n",
            "Training loss (for one batch) at step 0: 1.5042\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7009\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2092\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9954\n",
            "\n",
            "Start of epoch 173\n",
            "Training loss (for one batch) at step 0: 1.5788\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5042\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4104\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7363\n",
            "\n",
            "Start of epoch 174\n",
            "Training loss (for one batch) at step 0: 2.0137\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1340\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2505\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7182\n",
            "\n",
            "Start of epoch 175\n",
            "Training loss (for one batch) at step 0: 1.2315\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5596\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5528\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6750\n",
            "\n",
            "Start of epoch 176\n",
            "Training loss (for one batch) at step 0: 1.5906\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.9306\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5360\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6940\n",
            "\n",
            "Start of epoch 177\n",
            "Training loss (for one batch) at step 0: 1.6272\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1976\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5550\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.6778\n",
            "\n",
            "Start of epoch 178\n",
            "Training loss (for one batch) at step 0: 1.3726\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0945\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2806\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6962\n",
            "\n",
            "Start of epoch 179\n",
            "Training loss (for one batch) at step 0: 1.4089\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0315\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5347\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6744\n",
            "\n",
            "Start of epoch 180\n",
            "Training loss (for one batch) at step 0: 1.3851\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.1897\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0630\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8689\n",
            "\n",
            "Start of epoch 181\n",
            "Training loss (for one batch) at step 0: 1.5214\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3043\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6125\n",
            "\n",
            "Start of epoch 182\n",
            "Training loss (for one batch) at step 0: 1.4768\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4008\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3739\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9420\n",
            "\n",
            "Start of epoch 183\n",
            "Training loss (for one batch) at step 0: 1.2138\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6245\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8150\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1057\n",
            "\n",
            "Start of epoch 184\n",
            "Training loss (for one batch) at step 0: 1.2016\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3498\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3476\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5774\n",
            "\n",
            "Start of epoch 185\n",
            "Training loss (for one batch) at step 0: 1.2960\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1087\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.0028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4963\n",
            "\n",
            "Start of epoch 186\n",
            "Training loss (for one batch) at step 0: 1.2774\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1320\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3615\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8613\n",
            "\n",
            "Start of epoch 187\n",
            "Training loss (for one batch) at step 0: 0.9367\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2936\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4828\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5987\n",
            "\n",
            "Start of epoch 188\n",
            "Training loss (for one batch) at step 0: 1.3236\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1800\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2885\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6027\n",
            "\n",
            "Start of epoch 189\n",
            "Training loss (for one batch) at step 0: 1.1305\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1318\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8201\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7457\n",
            "\n",
            "Start of epoch 190\n",
            "Training loss (for one batch) at step 0: 1.2434\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3824\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8254\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9233\n",
            "\n",
            "Start of epoch 191\n",
            "Training loss (for one batch) at step 0: 1.1165\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1808\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5960\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1288\n",
            "\n",
            "Start of epoch 192\n",
            "Training loss (for one batch) at step 0: 1.3035\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5769\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0071\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7276\n",
            "\n",
            "Start of epoch 193\n",
            "Training loss (for one batch) at step 0: 1.7639\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4086\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3086\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5929\n",
            "\n",
            "Start of epoch 194\n",
            "Training loss (for one batch) at step 0: 1.1319\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4617\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7866\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7660\n",
            "\n",
            "Start of epoch 195\n",
            "Training loss (for one batch) at step 0: 1.4162\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4542\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0947\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8517\n",
            "\n",
            "Start of epoch 196\n",
            "Training loss (for one batch) at step 0: 1.3369\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0146\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2387\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7022\n",
            "\n",
            "Start of epoch 197\n",
            "Training loss (for one batch) at step 0: 1.0274\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3517\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2017\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9107\n",
            "\n",
            "Start of epoch 198\n",
            "Training loss (for one batch) at step 0: 1.3191\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3078\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0963\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0777\n",
            "\n",
            "Start of epoch 199\n",
            "Training loss (for one batch) at step 0: 1.0223\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9854\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0735\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.1431\n",
            "\n",
            "Start of epoch 200\n",
            "Training loss (for one batch) at step 0: 1.3475\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2679\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9629\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7054\n",
            "\n",
            "Start of epoch 201\n",
            "Training loss (for one batch) at step 0: 0.9543\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9215\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5543\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8276\n",
            "\n",
            "Start of epoch 202\n",
            "Training loss (for one batch) at step 0: 2.0011\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3024\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2689\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7176\n",
            "\n",
            "Start of epoch 203\n",
            "Training loss (for one batch) at step 0: 1.4340\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4414\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8063\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6263\n",
            "\n",
            "Start of epoch 204\n",
            "Training loss (for one batch) at step 0: 1.1422\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.2667\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1566\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5211\n",
            "\n",
            "Start of epoch 205\n",
            "Training loss (for one batch) at step 0: 1.5170\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4404\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1847\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5416\n",
            "\n",
            "Start of epoch 206\n",
            "Training loss (for one batch) at step 0: 1.2105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3288\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9107\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8553\n",
            "\n",
            "Start of epoch 207\n",
            "Training loss (for one batch) at step 0: 1.6613\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6323\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0210\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5792\n",
            "\n",
            "Start of epoch 208\n",
            "Training loss (for one batch) at step 0: 0.9294\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3578\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0760\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5148\n",
            "\n",
            "Start of epoch 209\n",
            "Training loss (for one batch) at step 0: 1.5028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1491\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2019\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3574\n",
            "\n",
            "Start of epoch 210\n",
            "Training loss (for one batch) at step 0: 1.1687\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3549\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5469\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5403\n",
            "\n",
            "Start of epoch 211\n",
            "Training loss (for one batch) at step 0: 1.0325\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4267\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2230\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3587\n",
            "\n",
            "Start of epoch 212\n",
            "Training loss (for one batch) at step 0: 1.3030\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4950\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7204\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4373\n",
            "\n",
            "Start of epoch 213\n",
            "Training loss (for one batch) at step 0: 1.5634\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4063\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0454\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4242\n",
            "\n",
            "Start of epoch 214\n",
            "Training loss (for one batch) at step 0: 1.5786\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2435\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3258\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5253\n",
            "\n",
            "Start of epoch 215\n",
            "Training loss (for one batch) at step 0: 1.1049\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0236\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9475\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6495\n",
            "\n",
            "Start of epoch 216\n",
            "Training loss (for one batch) at step 0: 0.8357\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0799\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7638\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4296\n",
            "\n",
            "Start of epoch 217\n",
            "Training loss (for one batch) at step 0: 1.4345\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0152\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0091\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6206\n",
            "\n",
            "Start of epoch 218\n",
            "Training loss (for one batch) at step 0: 1.0344\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0491\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3907\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5475\n",
            "\n",
            "Start of epoch 219\n",
            "Training loss (for one batch) at step 0: 1.0097\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2767\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2771\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6528\n",
            "\n",
            "Start of epoch 220\n",
            "Training loss (for one batch) at step 0: 1.3207\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3426\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4927\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6146\n",
            "\n",
            "Start of epoch 221\n",
            "Training loss (for one batch) at step 0: 0.9842\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.3908\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5757\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8169\n",
            "\n",
            "Start of epoch 222\n",
            "Training loss (for one batch) at step 0: 1.7290\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1218\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8459\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3991\n",
            "\n",
            "Start of epoch 223\n",
            "Training loss (for one batch) at step 0: 1.2797\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1147\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0497\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5589\n",
            "\n",
            "Start of epoch 224\n",
            "Training loss (for one batch) at step 0: 1.0019\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8875\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9340\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7198\n",
            "\n",
            "Start of epoch 225\n",
            "Training loss (for one batch) at step 0: 0.9107\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4711\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7002\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7253\n",
            "\n",
            "Start of epoch 226\n",
            "Training loss (for one batch) at step 0: 1.0515\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4920\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1373\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7863\n",
            "\n",
            "Start of epoch 227\n",
            "Training loss (for one batch) at step 0: 1.0510\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1264\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9344\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9712\n",
            "\n",
            "Start of epoch 228\n",
            "Training loss (for one batch) at step 0: 1.1199\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0114\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2220\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9542\n",
            "\n",
            "Start of epoch 229\n",
            "Training loss (for one batch) at step 0: 1.6525\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8525\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0275\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7483\n",
            "\n",
            "Start of epoch 230\n",
            "Training loss (for one batch) at step 0: 0.9888\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6547\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4380\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4454\n",
            "\n",
            "Start of epoch 231\n",
            "Training loss (for one batch) at step 0: 0.9056\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6808\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1616\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6282\n",
            "\n",
            "Start of epoch 232\n",
            "Training loss (for one batch) at step 0: 1.0997\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0004\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9219\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6711\n",
            "\n",
            "Start of epoch 233\n",
            "Training loss (for one batch) at step 0: 1.0589\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9538\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9537\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7611\n",
            "\n",
            "Start of epoch 234\n",
            "Training loss (for one batch) at step 0: 1.2122\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1246\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2679\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4717\n",
            "\n",
            "Start of epoch 235\n",
            "Training loss (for one batch) at step 0: 1.4702\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9943\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9689\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7852\n",
            "\n",
            "Start of epoch 236\n",
            "Training loss (for one batch) at step 0: 1.3407\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1390\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9060\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6230\n",
            "\n",
            "Start of epoch 237\n",
            "Training loss (for one batch) at step 0: 0.9494\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2196\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 2.3370\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4571\n",
            "\n",
            "Start of epoch 238\n",
            "Training loss (for one batch) at step 0: 0.9680\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2797\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2105\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6602\n",
            "\n",
            "Start of epoch 239\n",
            "Training loss (for one batch) at step 0: 0.8601\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7031\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8929\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3703\n",
            "\n",
            "Start of epoch 240\n",
            "Training loss (for one batch) at step 0: 1.0997\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4334\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0409\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8825\n",
            "\n",
            "Start of epoch 241\n",
            "Training loss (for one batch) at step 0: 0.9282\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8625\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2936\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5224\n",
            "\n",
            "Start of epoch 242\n",
            "Training loss (for one batch) at step 0: 1.0381\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7220\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6892\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8266\n",
            "\n",
            "Start of epoch 243\n",
            "Training loss (for one batch) at step 0: 0.8926\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0618\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1565\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6043\n",
            "\n",
            "Start of epoch 244\n",
            "Training loss (for one batch) at step 0: 1.1226\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9448\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4611\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4196\n",
            "\n",
            "Start of epoch 245\n",
            "Training loss (for one batch) at step 0: 0.9801\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9789\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3825\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6576\n",
            "\n",
            "Start of epoch 246\n",
            "Training loss (for one batch) at step 0: 1.3340\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8572\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2866\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3714\n",
            "\n",
            "Start of epoch 247\n",
            "Training loss (for one batch) at step 0: 1.3524\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0496\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1088\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5224\n",
            "\n",
            "Start of epoch 248\n",
            "Training loss (for one batch) at step 0: 1.8186\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8515\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6250\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3997\n",
            "\n",
            "Start of epoch 249\n",
            "Training loss (for one batch) at step 0: 0.9415\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1436\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9409\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5939\n",
            "\n",
            "Start of epoch 250\n",
            "Training loss (for one batch) at step 0: 0.8614\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3792\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9236\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4733\n",
            "\n",
            "Start of epoch 251\n",
            "Training loss (for one batch) at step 0: 0.7997\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.6365\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2239\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6241\n",
            "\n",
            "Start of epoch 252\n",
            "Training loss (for one batch) at step 0: 1.0610\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2582\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9681\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7830\n",
            "\n",
            "Start of epoch 253\n",
            "Training loss (for one batch) at step 0: 1.2835\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9195\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9154\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5007\n",
            "\n",
            "Start of epoch 254\n",
            "Training loss (for one batch) at step 0: 1.2999\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9887\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1841\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4436\n",
            "\n",
            "Start of epoch 255\n",
            "Training loss (for one batch) at step 0: 1.3940\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1285\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4175\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5876\n",
            "\n",
            "Start of epoch 256\n",
            "Training loss (for one batch) at step 0: 0.8168\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9203\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8124\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4730\n",
            "\n",
            "Start of epoch 257\n",
            "Training loss (for one batch) at step 0: 0.9665\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2271\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1423\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6575\n",
            "\n",
            "Start of epoch 258\n",
            "Training loss (for one batch) at step 0: 1.0862\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0820\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1551\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7572\n",
            "\n",
            "Start of epoch 259\n",
            "Training loss (for one batch) at step 0: 1.1958\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3583\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2242\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4802\n",
            "\n",
            "Start of epoch 260\n",
            "Training loss (for one batch) at step 0: 1.1903\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9078\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2115\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4887\n",
            "\n",
            "Start of epoch 261\n",
            "Training loss (for one batch) at step 0: 1.2370\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9788\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4083\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5931\n",
            "\n",
            "Start of epoch 262\n",
            "Training loss (for one batch) at step 0: 1.2373\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4504\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8527\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7393\n",
            "\n",
            "Start of epoch 263\n",
            "Training loss (for one batch) at step 0: 1.3434\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1138\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1036\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5043\n",
            "\n",
            "Start of epoch 264\n",
            "Training loss (for one batch) at step 0: 1.2658\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3260\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0697\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5349\n",
            "\n",
            "Start of epoch 265\n",
            "Training loss (for one batch) at step 0: 1.2841\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2880\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1756\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7440\n",
            "\n",
            "Start of epoch 266\n",
            "Training loss (for one batch) at step 0: 0.9769\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4111\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0435\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6345\n",
            "\n",
            "Start of epoch 267\n",
            "Training loss (for one batch) at step 0: 0.8164\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8099\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8710\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5727\n",
            "\n",
            "Start of epoch 268\n",
            "Training loss (for one batch) at step 0: 0.8539\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0980\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9584\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8287\n",
            "\n",
            "Start of epoch 269\n",
            "Training loss (for one batch) at step 0: 1.0766\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9350\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3066\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5970\n",
            "\n",
            "Start of epoch 270\n",
            "Training loss (for one batch) at step 0: 1.1627\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0695\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8166\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6682\n",
            "\n",
            "Start of epoch 271\n",
            "Training loss (for one batch) at step 0: 1.0479\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8660\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8704\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0693\n",
            "\n",
            "Start of epoch 272\n",
            "Training loss (for one batch) at step 0: 1.2467\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8951\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3322\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4709\n",
            "\n",
            "Start of epoch 273\n",
            "Training loss (for one batch) at step 0: 0.9013\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3255\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7778\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6108\n",
            "\n",
            "Start of epoch 274\n",
            "Training loss (for one batch) at step 0: 1.1881\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9075\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5965\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6289\n",
            "\n",
            "Start of epoch 275\n",
            "Training loss (for one batch) at step 0: 1.0105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1860\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1243\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5310\n",
            "\n",
            "Start of epoch 276\n",
            "Training loss (for one batch) at step 0: 1.0142\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4554\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0441\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4829\n",
            "\n",
            "Start of epoch 277\n",
            "Training loss (for one batch) at step 0: 0.9591\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3069\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2597\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5368\n",
            "\n",
            "Start of epoch 278\n",
            "Training loss (for one batch) at step 0: 1.0778\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3405\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8824\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6000\n",
            "\n",
            "Start of epoch 279\n",
            "Training loss (for one batch) at step 0: 1.1291\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9554\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4493\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8546\n",
            "\n",
            "Start of epoch 280\n",
            "Training loss (for one batch) at step 0: 1.0452\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2879\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8688\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6745\n",
            "\n",
            "Start of epoch 281\n",
            "Training loss (for one batch) at step 0: 1.0369\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4642\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1099\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6622\n",
            "\n",
            "Start of epoch 282\n",
            "Training loss (for one batch) at step 0: 1.5473\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1283\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8723\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6313\n",
            "\n",
            "Start of epoch 283\n",
            "Training loss (for one batch) at step 0: 0.7447\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0439\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4655\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7091\n",
            "\n",
            "Start of epoch 284\n",
            "Training loss (for one batch) at step 0: 0.8629\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9861\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0337\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4586\n",
            "\n",
            "Start of epoch 285\n",
            "Training loss (for one batch) at step 0: 0.7962\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2227\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0086\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4689\n",
            "\n",
            "Start of epoch 286\n",
            "Training loss (for one batch) at step 0: 0.8951\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9750\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6528\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5474\n",
            "\n",
            "Start of epoch 287\n",
            "Training loss (for one batch) at step 0: 1.2891\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0007\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0186\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5186\n",
            "\n",
            "Start of epoch 288\n",
            "Training loss (for one batch) at step 0: 1.3760\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9006\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0695\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0304\n",
            "\n",
            "Start of epoch 289\n",
            "Training loss (for one batch) at step 0: 1.3774\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1439\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1384\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9102\n",
            "\n",
            "Start of epoch 290\n",
            "Training loss (for one batch) at step 0: 1.4171\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3563\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0499\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8552\n",
            "\n",
            "Start of epoch 291\n",
            "Training loss (for one batch) at step 0: 1.2409\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3866\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8621\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6541\n",
            "\n",
            "Start of epoch 292\n",
            "Training loss (for one batch) at step 0: 1.0199\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8917\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8867\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6389\n",
            "\n",
            "Start of epoch 293\n",
            "Training loss (for one batch) at step 0: 1.0955\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0518\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5076\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4765\n",
            "\n",
            "Start of epoch 294\n",
            "Training loss (for one batch) at step 0: 0.8155\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8432\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7689\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6905\n",
            "\n",
            "Start of epoch 295\n",
            "Training loss (for one batch) at step 0: 0.7704\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5212\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0299\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7925\n",
            "\n",
            "Start of epoch 296\n",
            "Training loss (for one batch) at step 0: 0.9681\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9618\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0843\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4550\n",
            "\n",
            "Start of epoch 297\n",
            "Training loss (for one batch) at step 0: 0.8869\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3038\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7770\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5114\n",
            "\n",
            "Start of epoch 298\n",
            "Training loss (for one batch) at step 0: 0.9067\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4254\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5335\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4277\n",
            "\n",
            "Start of epoch 299\n",
            "Training loss (for one batch) at step 0: 0.9428\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1916\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9460\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5791\n",
            "\n",
            "Start of epoch 300\n",
            "Training loss (for one batch) at step 0: 1.5521\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3343\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4284\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4454\n",
            "\n",
            "Start of epoch 301\n",
            "Training loss (for one batch) at step 0: 1.0881\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8739\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2516\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4668\n",
            "\n",
            "Start of epoch 302\n",
            "Training loss (for one batch) at step 0: 1.3197\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8836\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7942\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4965\n",
            "\n",
            "Start of epoch 303\n",
            "Training loss (for one batch) at step 0: 0.9757\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1625\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8868\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6096\n",
            "\n",
            "Start of epoch 304\n",
            "Training loss (for one batch) at step 0: 0.8351\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8430\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1951\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4576\n",
            "\n",
            "Start of epoch 305\n",
            "Training loss (for one batch) at step 0: 1.2817\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9413\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4171\n",
            "\n",
            "Start of epoch 306\n",
            "Training loss (for one batch) at step 0: 0.9760\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0120\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0648\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3313\n",
            "\n",
            "Start of epoch 307\n",
            "Training loss (for one batch) at step 0: 0.9356\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9158\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2342\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6247\n",
            "\n",
            "Start of epoch 308\n",
            "Training loss (for one batch) at step 0: 1.1765\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0384\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0176\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9655\n",
            "\n",
            "Start of epoch 309\n",
            "Training loss (for one batch) at step 0: 1.3599\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4445\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9764\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7479\n",
            "\n",
            "Start of epoch 310\n",
            "Training loss (for one batch) at step 0: 0.6935\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2352\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8139\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5659\n",
            "\n",
            "Start of epoch 311\n",
            "Training loss (for one batch) at step 0: 0.7931\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7716\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8169\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4627\n",
            "\n",
            "Start of epoch 312\n",
            "Training loss (for one batch) at step 0: 1.0619\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9588\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5353\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4383\n",
            "\n",
            "Start of epoch 313\n",
            "Training loss (for one batch) at step 0: 0.7763\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8391\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8154\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8288\n",
            "\n",
            "Start of epoch 314\n",
            "Training loss (for one batch) at step 0: 0.8318\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0453\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4865\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5399\n",
            "\n",
            "Start of epoch 315\n",
            "Training loss (for one batch) at step 0: 1.7077\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0475\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4093\n",
            "\n",
            "Start of epoch 316\n",
            "Training loss (for one batch) at step 0: 1.2486\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8174\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0168\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6303\n",
            "\n",
            "Start of epoch 317\n",
            "Training loss (for one batch) at step 0: 1.7850\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3494\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9346\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4762\n",
            "\n",
            "Start of epoch 318\n",
            "Training loss (for one batch) at step 0: 1.3170\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9406\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5797\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4925\n",
            "\n",
            "Start of epoch 319\n",
            "Training loss (for one batch) at step 0: 1.6668\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8755\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1448\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.3361\n",
            "\n",
            "Start of epoch 320\n",
            "Training loss (for one batch) at step 0: 1.1571\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9401\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0056\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9565\n",
            "\n",
            "Start of epoch 321\n",
            "Training loss (for one batch) at step 0: 1.1607\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7914\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7775\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5986\n",
            "\n",
            "Start of epoch 322\n",
            "Training loss (for one batch) at step 0: 1.0609\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8385\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1803\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7245\n",
            "\n",
            "Start of epoch 323\n",
            "Training loss (for one batch) at step 0: 1.2662\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7188\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3070\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0826\n",
            "\n",
            "Start of epoch 324\n",
            "Training loss (for one batch) at step 0: 1.4263\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9014\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3187\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4532\n",
            "\n",
            "Start of epoch 325\n",
            "Training loss (for one batch) at step 0: 0.7483\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8368\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8261\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5449\n",
            "\n",
            "Start of epoch 326\n",
            "Training loss (for one batch) at step 0: 0.9004\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4105\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3080\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5508\n",
            "\n",
            "Start of epoch 327\n",
            "Training loss (for one batch) at step 0: 1.0627\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8237\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7883\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4223\n",
            "\n",
            "Start of epoch 328\n",
            "Training loss (for one batch) at step 0: 2.1038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0931\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4034\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5292\n",
            "\n",
            "Start of epoch 329\n",
            "Training loss (for one batch) at step 0: 0.9344\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1065\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6138\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4773\n",
            "\n",
            "Start of epoch 330\n",
            "Training loss (for one batch) at step 0: 0.8514\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8680\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2024\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4111\n",
            "\n",
            "Start of epoch 331\n",
            "Training loss (for one batch) at step 0: 0.9573\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7377\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8108\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7607\n",
            "\n",
            "Start of epoch 332\n",
            "Training loss (for one batch) at step 0: 0.8440\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8493\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8292\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4394\n",
            "\n",
            "Start of epoch 333\n",
            "Training loss (for one batch) at step 0: 1.2998\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1795\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1689\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5139\n",
            "\n",
            "Start of epoch 334\n",
            "Training loss (for one batch) at step 0: 0.8038\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8819\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2021\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4184\n",
            "\n",
            "Start of epoch 335\n",
            "Training loss (for one batch) at step 0: 0.9033\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7033\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9771\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4590\n",
            "\n",
            "Start of epoch 336\n",
            "Training loss (for one batch) at step 0: 1.2489\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2171\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9628\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6212\n",
            "\n",
            "Start of epoch 337\n",
            "Training loss (for one batch) at step 0: 1.3117\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9846\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5848\n",
            "\n",
            "Start of epoch 338\n",
            "Training loss (for one batch) at step 0: 1.0309\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0896\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8321\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7030\n",
            "\n",
            "Start of epoch 339\n",
            "Training loss (for one batch) at step 0: 1.2604\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7714\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8822\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5666\n",
            "\n",
            "Start of epoch 340\n",
            "Training loss (for one batch) at step 0: 1.3555\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9142\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3204\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4780\n",
            "\n",
            "Start of epoch 341\n",
            "Training loss (for one batch) at step 0: 0.9452\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1857\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9106\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7933\n",
            "\n",
            "Start of epoch 342\n",
            "Training loss (for one batch) at step 0: 0.9321\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2814\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0495\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3947\n",
            "\n",
            "Start of epoch 343\n",
            "Training loss (for one batch) at step 0: 0.6947\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8854\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0404\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5915\n",
            "\n",
            "Start of epoch 344\n",
            "Training loss (for one batch) at step 0: 1.3008\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9751\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8316\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7120\n",
            "\n",
            "Start of epoch 345\n",
            "Training loss (for one batch) at step 0: 1.5694\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0681\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3726\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4685\n",
            "\n",
            "Start of epoch 346\n",
            "Training loss (for one batch) at step 0: 0.8617\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8994\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2093\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6318\n",
            "\n",
            "Start of epoch 347\n",
            "Training loss (for one batch) at step 0: 0.8020\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9108\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9649\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5892\n",
            "\n",
            "Start of epoch 348\n",
            "Training loss (for one batch) at step 0: 0.8858\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9915\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8473\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3195\n",
            "\n",
            "Start of epoch 349\n",
            "Training loss (for one batch) at step 0: 1.1793\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7725\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0568\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3995\n",
            "\n",
            "Start of epoch 350\n",
            "Training loss (for one batch) at step 0: 0.9260\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9126\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0058\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5271\n",
            "\n",
            "Start of epoch 351\n",
            "Training loss (for one batch) at step 0: 1.0200\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9608\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9838\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4208\n",
            "\n",
            "Start of epoch 352\n",
            "Training loss (for one batch) at step 0: 1.3469\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2370\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7058\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4322\n",
            "\n",
            "Start of epoch 353\n",
            "Training loss (for one batch) at step 0: 1.0286\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1533\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2369\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6393\n",
            "\n",
            "Start of epoch 354\n",
            "Training loss (for one batch) at step 0: 0.9958\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.8746\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9379\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4391\n",
            "\n",
            "Start of epoch 355\n",
            "Training loss (for one batch) at step 0: 0.9443\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8411\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6248\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7986\n",
            "\n",
            "Start of epoch 356\n",
            "Training loss (for one batch) at step 0: 1.0141\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5853\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8191\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5432\n",
            "\n",
            "Start of epoch 357\n",
            "Training loss (for one batch) at step 0: 1.0352\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9511\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9986\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3922\n",
            "\n",
            "Start of epoch 358\n",
            "Training loss (for one batch) at step 0: 1.1105\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8341\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0025\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7122\n",
            "\n",
            "Start of epoch 359\n",
            "Training loss (for one batch) at step 0: 0.7676\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2661\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4243\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5824\n",
            "\n",
            "Start of epoch 360\n",
            "Training loss (for one batch) at step 0: 1.6082\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9650\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4839\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4303\n",
            "\n",
            "Start of epoch 361\n",
            "Training loss (for one batch) at step 0: 0.7553\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7984\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9431\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8527\n",
            "\n",
            "Start of epoch 362\n",
            "Training loss (for one batch) at step 0: 0.7064\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8572\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1419\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8705\n",
            "\n",
            "Start of epoch 363\n",
            "Training loss (for one batch) at step 0: 0.8843\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9499\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9149\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4940\n",
            "\n",
            "Start of epoch 364\n",
            "Training loss (for one batch) at step 0: 0.8524\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9554\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1976\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5822\n",
            "\n",
            "Start of epoch 365\n",
            "Training loss (for one batch) at step 0: 0.7740\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0169\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8673\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5601\n",
            "\n",
            "Start of epoch 366\n",
            "Training loss (for one batch) at step 0: 0.8863\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3009\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3571\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6609\n",
            "\n",
            "Start of epoch 367\n",
            "Training loss (for one batch) at step 0: 0.9122\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8877\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9339\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7216\n",
            "\n",
            "Start of epoch 368\n",
            "Training loss (for one batch) at step 0: 0.9220\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1770\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4758\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3933\n",
            "\n",
            "Start of epoch 369\n",
            "Training loss (for one batch) at step 0: 0.7540\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3350\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8264\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3792\n",
            "\n",
            "Start of epoch 370\n",
            "Training loss (for one batch) at step 0: 0.8109\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7867\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9466\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5186\n",
            "\n",
            "Start of epoch 371\n",
            "Training loss (for one batch) at step 0: 0.7762\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4308\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3699\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4059\n",
            "\n",
            "Start of epoch 372\n",
            "Training loss (for one batch) at step 0: 0.9574\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2055\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0578\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4902\n",
            "\n",
            "Start of epoch 373\n",
            "Training loss (for one batch) at step 0: 0.8424\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0171\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0934\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4815\n",
            "\n",
            "Start of epoch 374\n",
            "Training loss (for one batch) at step 0: 1.3969\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2826\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2289\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5061\n",
            "\n",
            "Start of epoch 375\n",
            "Training loss (for one batch) at step 0: 0.8135\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3979\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9623\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6053\n",
            "\n",
            "Start of epoch 376\n",
            "Training loss (for one batch) at step 0: 0.8222\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8651\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2250\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3685\n",
            "\n",
            "Start of epoch 377\n",
            "Training loss (for one batch) at step 0: 1.0083\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7517\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7785\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7546\n",
            "\n",
            "Start of epoch 378\n",
            "Training loss (for one batch) at step 0: 0.7709\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8823\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8838\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4388\n",
            "\n",
            "Start of epoch 379\n",
            "Training loss (for one batch) at step 0: 0.8053\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4215\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8151\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5033\n",
            "\n",
            "Start of epoch 380\n",
            "Training loss (for one batch) at step 0: 1.6353\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3070\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1028\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6393\n",
            "\n",
            "Start of epoch 381\n",
            "Training loss (for one batch) at step 0: 1.3161\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3731\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9231\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5377\n",
            "\n",
            "Start of epoch 382\n",
            "Training loss (for one batch) at step 0: 1.2985\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0467\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7617\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4713\n",
            "\n",
            "Start of epoch 383\n",
            "Training loss (for one batch) at step 0: 1.2529\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.6950\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5734\n",
            "\n",
            "Start of epoch 384\n",
            "Training loss (for one batch) at step 0: 0.6853\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0660\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9474\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4225\n",
            "\n",
            "Start of epoch 385\n",
            "Training loss (for one batch) at step 0: 1.4494\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2833\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8030\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5194\n",
            "\n",
            "Start of epoch 386\n",
            "Training loss (for one batch) at step 0: 0.9844\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3091\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0329\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4117\n",
            "\n",
            "Start of epoch 387\n",
            "Training loss (for one batch) at step 0: 0.9929\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7668\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7766\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5210\n",
            "\n",
            "Start of epoch 388\n",
            "Training loss (for one batch) at step 0: 1.0495\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8951\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4366\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3849\n",
            "\n",
            "Start of epoch 389\n",
            "Training loss (for one batch) at step 0: 0.8150\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.7588\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3384\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5475\n",
            "\n",
            "Start of epoch 390\n",
            "Training loss (for one batch) at step 0: 1.2759\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9244\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.7145\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4518\n",
            "\n",
            "Start of epoch 391\n",
            "Training loss (for one batch) at step 0: 0.9998\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2555\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1481\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4176\n",
            "\n",
            "Start of epoch 392\n",
            "Training loss (for one batch) at step 0: 0.8844\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7738\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8989\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7511\n",
            "\n",
            "Start of epoch 393\n",
            "Training loss (for one batch) at step 0: 1.2058\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8388\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3062\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7308\n",
            "\n",
            "Start of epoch 394\n",
            "Training loss (for one batch) at step 0: 1.0332\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9029\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9590\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3862\n",
            "\n",
            "Start of epoch 395\n",
            "Training loss (for one batch) at step 0: 0.8733\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.6966\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9346\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3214\n",
            "\n",
            "Start of epoch 396\n",
            "Training loss (for one batch) at step 0: 0.9577\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9454\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6474\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6160\n",
            "\n",
            "Start of epoch 397\n",
            "Training loss (for one batch) at step 0: 1.1357\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0481\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7554\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7418\n",
            "\n",
            "Start of epoch 398\n",
            "Training loss (for one batch) at step 0: 0.8028\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3258\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7269\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8842\n",
            "\n",
            "Start of epoch 399\n",
            "Training loss (for one batch) at step 0: 1.0320\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8296\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3113\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4689\n",
            "\n",
            "Start of epoch 400\n",
            "Training loss (for one batch) at step 0: 0.7373\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8648\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3413\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9459\n",
            "\n",
            "Start of epoch 401\n",
            "Training loss (for one batch) at step 0: 0.8293\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7944\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9494\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4774\n",
            "\n",
            "Start of epoch 402\n",
            "Training loss (for one batch) at step 0: 1.0936\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3865\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5519\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6798\n",
            "\n",
            "Start of epoch 403\n",
            "Training loss (for one batch) at step 0: 0.8121\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3165\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.5051\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3766\n",
            "\n",
            "Start of epoch 404\n",
            "Training loss (for one batch) at step 0: 0.9659\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0676\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8527\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4053\n",
            "\n",
            "Start of epoch 405\n",
            "Training loss (for one batch) at step 0: 0.9376\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8959\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9260\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6130\n",
            "\n",
            "Start of epoch 406\n",
            "Training loss (for one batch) at step 0: 0.8256\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1587\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0396\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5510\n",
            "\n",
            "Start of epoch 407\n",
            "Training loss (for one batch) at step 0: 1.1979\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9483\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0493\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4241\n",
            "\n",
            "Start of epoch 408\n",
            "Training loss (for one batch) at step 0: 1.5755\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8110\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0349\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6149\n",
            "\n",
            "Start of epoch 409\n",
            "Training loss (for one batch) at step 0: 1.0673\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2783\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8960\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4591\n",
            "\n",
            "Start of epoch 410\n",
            "Training loss (for one batch) at step 0: 0.8748\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0771\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1486\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4393\n",
            "\n",
            "Start of epoch 411\n",
            "Training loss (for one batch) at step 0: 1.3559\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8787\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0019\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4837\n",
            "\n",
            "Start of epoch 412\n",
            "Training loss (for one batch) at step 0: 1.3765\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1407\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8405\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4633\n",
            "\n",
            "Start of epoch 413\n",
            "Training loss (for one batch) at step 0: 0.8551\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9047\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8440\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4905\n",
            "\n",
            "Start of epoch 414\n",
            "Training loss (for one batch) at step 0: 0.8352\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1007\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8954\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5651\n",
            "\n",
            "Start of epoch 415\n",
            "Training loss (for one batch) at step 0: 1.0767\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7271\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1916\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5490\n",
            "\n",
            "Start of epoch 416\n",
            "Training loss (for one batch) at step 0: 1.1565\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0628\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9941\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6492\n",
            "\n",
            "Start of epoch 417\n",
            "Training loss (for one batch) at step 0: 0.8631\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1664\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3701\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6603\n",
            "\n",
            "Start of epoch 418\n",
            "Training loss (for one batch) at step 0: 0.7962\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9731\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7993\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5402\n",
            "\n",
            "Start of epoch 419\n",
            "Training loss (for one batch) at step 0: 1.2797\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8221\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8968\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5581\n",
            "\n",
            "Start of epoch 420\n",
            "Training loss (for one batch) at step 0: 1.3723\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0015\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0712\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4597\n",
            "\n",
            "Start of epoch 421\n",
            "Training loss (for one batch) at step 0: 0.8681\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8065\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0265\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5028\n",
            "\n",
            "Start of epoch 422\n",
            "Training loss (for one batch) at step 0: 0.7599\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9591\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1039\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5562\n",
            "\n",
            "Start of epoch 423\n",
            "Training loss (for one batch) at step 0: 0.9804\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8483\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0400\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4336\n",
            "\n",
            "Start of epoch 424\n",
            "Training loss (for one batch) at step 0: 0.9186\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2988\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7747\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6552\n",
            "\n",
            "Start of epoch 425\n",
            "Training loss (for one batch) at step 0: 0.8496\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0683\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6814\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3538\n",
            "\n",
            "Start of epoch 426\n",
            "Training loss (for one batch) at step 0: 1.2274\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9068\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7022\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4882\n",
            "\n",
            "Start of epoch 427\n",
            "Training loss (for one batch) at step 0: 0.7448\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8203\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9820\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6805\n",
            "\n",
            "Start of epoch 428\n",
            "Training loss (for one batch) at step 0: 0.7413\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9190\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7201\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3639\n",
            "\n",
            "Start of epoch 429\n",
            "Training loss (for one batch) at step 0: 0.9705\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0095\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.6593\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5751\n",
            "\n",
            "Start of epoch 430\n",
            "Training loss (for one batch) at step 0: 1.4040\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9307\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8987\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5998\n",
            "\n",
            "Start of epoch 431\n",
            "Training loss (for one batch) at step 0: 1.1617\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9247\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9539\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7305\n",
            "\n",
            "Start of epoch 432\n",
            "Training loss (for one batch) at step 0: 1.3169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8782\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7750\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4744\n",
            "\n",
            "Start of epoch 433\n",
            "Training loss (for one batch) at step 0: 0.8325\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2686\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8394\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5023\n",
            "\n",
            "Start of epoch 434\n",
            "Training loss (for one batch) at step 0: 1.3786\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7216\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3066\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5023\n",
            "\n",
            "Start of epoch 435\n",
            "Training loss (for one batch) at step 0: 1.0829\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0270\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8815\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4634\n",
            "\n",
            "Start of epoch 436\n",
            "Training loss (for one batch) at step 0: 1.6227\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9300\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8012\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5240\n",
            "\n",
            "Start of epoch 437\n",
            "Training loss (for one batch) at step 0: 1.0252\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9961\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2345\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3943\n",
            "\n",
            "Start of epoch 438\n",
            "Training loss (for one batch) at step 0: 0.7571\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4645\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2270\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6196\n",
            "\n",
            "Start of epoch 439\n",
            "Training loss (for one batch) at step 0: 0.9756\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8640\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1907\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6472\n",
            "\n",
            "Start of epoch 440\n",
            "Training loss (for one batch) at step 0: 1.6593\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 2.0710\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4356\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4209\n",
            "\n",
            "Start of epoch 441\n",
            "Training loss (for one batch) at step 0: 0.8664\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8842\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8881\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5485\n",
            "\n",
            "Start of epoch 442\n",
            "Training loss (for one batch) at step 0: 0.9456\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0884\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7464\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7749\n",
            "\n",
            "Start of epoch 443\n",
            "Training loss (for one batch) at step 0: 1.1163\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8467\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9668\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4706\n",
            "\n",
            "Start of epoch 444\n",
            "Training loss (for one batch) at step 0: 0.9600\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0056\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3602\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4967\n",
            "\n",
            "Start of epoch 445\n",
            "Training loss (for one batch) at step 0: 0.9594\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7805\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2091\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7793\n",
            "\n",
            "Start of epoch 446\n",
            "Training loss (for one batch) at step 0: 0.7919\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8236\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9283\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5700\n",
            "\n",
            "Start of epoch 447\n",
            "Training loss (for one batch) at step 0: 1.2169\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9487\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8067\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5539\n",
            "\n",
            "Start of epoch 448\n",
            "Training loss (for one batch) at step 0: 0.9871\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1798\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4135\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7990\n",
            "\n",
            "Start of epoch 449\n",
            "Training loss (for one batch) at step 0: 1.1013\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7693\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3092\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5223\n",
            "\n",
            "Start of epoch 450\n",
            "Training loss (for one batch) at step 0: 0.7017\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1798\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7513\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4670\n",
            "\n",
            "Start of epoch 451\n",
            "Training loss (for one batch) at step 0: 1.6727\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3647\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1139\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5472\n",
            "\n",
            "Start of epoch 452\n",
            "Training loss (for one batch) at step 0: 0.8779\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8792\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0518\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5206\n",
            "\n",
            "Start of epoch 453\n",
            "Training loss (for one batch) at step 0: 1.1008\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8253\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8709\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5249\n",
            "\n",
            "Start of epoch 454\n",
            "Training loss (for one batch) at step 0: 1.3632\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9076\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7194\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4412\n",
            "\n",
            "Start of epoch 455\n",
            "Training loss (for one batch) at step 0: 0.7931\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8169\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8280\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4599\n",
            "\n",
            "Start of epoch 456\n",
            "Training loss (for one batch) at step 0: 1.1762\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2058\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8063\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4251\n",
            "\n",
            "Start of epoch 457\n",
            "Training loss (for one batch) at step 0: 1.1838\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0163\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4447\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6680\n",
            "\n",
            "Start of epoch 458\n",
            "Training loss (for one batch) at step 0: 0.8646\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0083\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1467\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4090\n",
            "\n",
            "Start of epoch 459\n",
            "Training loss (for one batch) at step 0: 1.1791\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8845\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8083\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7729\n",
            "\n",
            "Start of epoch 460\n",
            "Training loss (for one batch) at step 0: 0.8874\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9333\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7299\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7430\n",
            "\n",
            "Start of epoch 461\n",
            "Training loss (for one batch) at step 0: 1.0278\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2483\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8600\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5126\n",
            "\n",
            "Start of epoch 462\n",
            "Training loss (for one batch) at step 0: 1.2094\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5749\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9662\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4319\n",
            "\n",
            "Start of epoch 463\n",
            "Training loss (for one batch) at step 0: 0.7435\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8140\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1185\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4025\n",
            "\n",
            "Start of epoch 464\n",
            "Training loss (for one batch) at step 0: 1.4946\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8149\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2015\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8090\n",
            "\n",
            "Start of epoch 465\n",
            "Training loss (for one batch) at step 0: 0.9523\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8362\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2080\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5269\n",
            "\n",
            "Start of epoch 466\n",
            "Training loss (for one batch) at step 0: 1.0166\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7889\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8759\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7356\n",
            "\n",
            "Start of epoch 467\n",
            "Training loss (for one batch) at step 0: 0.7324\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0262\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.4866\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7496\n",
            "\n",
            "Start of epoch 468\n",
            "Training loss (for one batch) at step 0: 1.0247\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7137\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2722\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 1.0872\n",
            "\n",
            "Start of epoch 469\n",
            "Training loss (for one batch) at step 0: 0.8885\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8173\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7386\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4750\n",
            "\n",
            "Start of epoch 470\n",
            "Training loss (for one batch) at step 0: 1.0104\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7702\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1307\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5769\n",
            "\n",
            "Start of epoch 471\n",
            "Training loss (for one batch) at step 0: 0.6914\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7885\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7867\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5110\n",
            "\n",
            "Start of epoch 472\n",
            "Training loss (for one batch) at step 0: 0.9141\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7863\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9278\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5305\n",
            "\n",
            "Start of epoch 473\n",
            "Training loss (for one batch) at step 0: 1.4471\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7842\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9948\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5730\n",
            "\n",
            "Start of epoch 474\n",
            "Training loss (for one batch) at step 0: 1.1776\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2164\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9575\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3267\n",
            "\n",
            "Start of epoch 475\n",
            "Training loss (for one batch) at step 0: 0.8928\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9712\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1604\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.7247\n",
            "\n",
            "Start of epoch 476\n",
            "Training loss (for one batch) at step 0: 0.8872\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1349\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9932\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4781\n",
            "\n",
            "Start of epoch 477\n",
            "Training loss (for one batch) at step 0: 0.8591\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7325\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1852\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.9865\n",
            "\n",
            "Start of epoch 478\n",
            "Training loss (for one batch) at step 0: 1.4980\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8211\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1686\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4542\n",
            "\n",
            "Start of epoch 479\n",
            "Training loss (for one batch) at step 0: 1.1310\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7257\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6682\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5316\n",
            "\n",
            "Start of epoch 480\n",
            "Training loss (for one batch) at step 0: 0.8583\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0809\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0329\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4696\n",
            "\n",
            "Start of epoch 481\n",
            "Training loss (for one batch) at step 0: 1.0552\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9542\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3063\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4584\n",
            "\n",
            "Start of epoch 482\n",
            "Training loss (for one batch) at step 0: 0.7814\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0857\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8331\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3449\n",
            "\n",
            "Start of epoch 483\n",
            "Training loss (for one batch) at step 0: 1.1423\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8394\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.3498\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4840\n",
            "\n",
            "Start of epoch 484\n",
            "Training loss (for one batch) at step 0: 0.9551\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4149\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6639\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5223\n",
            "\n",
            "Start of epoch 485\n",
            "Training loss (for one batch) at step 0: 1.0199\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7381\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8554\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6488\n",
            "\n",
            "Start of epoch 486\n",
            "Training loss (for one batch) at step 0: 0.8589\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.4978\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.1224\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5936\n",
            "\n",
            "Start of epoch 487\n",
            "Training loss (for one batch) at step 0: 0.7976\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3701\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7310\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.6519\n",
            "\n",
            "Start of epoch 488\n",
            "Training loss (for one batch) at step 0: 1.0164\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.5527\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8023\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4310\n",
            "\n",
            "Start of epoch 489\n",
            "Training loss (for one batch) at step 0: 0.6715\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.7429\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7559\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4767\n",
            "\n",
            "Start of epoch 490\n",
            "Training loss (for one batch) at step 0: 1.0626\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0284\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9894\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5293\n",
            "\n",
            "Start of epoch 491\n",
            "Training loss (for one batch) at step 0: 0.7467\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.3265\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.7086\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.8584\n",
            "\n",
            "Start of epoch 492\n",
            "Training loss (for one batch) at step 0: 0.7196\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8378\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8649\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3725\n",
            "\n",
            "Start of epoch 493\n",
            "Training loss (for one batch) at step 0: 0.9109\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.9283\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.0492\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5298\n",
            "\n",
            "Start of epoch 494\n",
            "Training loss (for one batch) at step 0: 0.8318\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.1598\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.8873\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5636\n",
            "\n",
            "Start of epoch 495\n",
            "Training loss (for one batch) at step 0: 1.1732\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8670\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.9675\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4712\n",
            "\n",
            "Start of epoch 496\n",
            "Training loss (for one batch) at step 0: 0.9016\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2386\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.9913\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4858\n",
            "\n",
            "Start of epoch 497\n",
            "Training loss (for one batch) at step 0: 0.8975\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.0459\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 0.6495\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.4687\n",
            "\n",
            "Start of epoch 498\n",
            "Training loss (for one batch) at step 0: 1.1626\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 1.2141\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.2634\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.5047\n",
            "\n",
            "Start of epoch 499\n",
            "Training loss (for one batch) at step 0: 0.7638\n",
            "seen so far: 100 samples\n",
            "Training loss (for one batch) at step 10: 0.8932\n",
            "seen so far: 1100 samples\n",
            "Training loss (for one batch) at step 20: 1.8958\n",
            "seen so far: 2100 samples\n",
            "validation MSE: 0.3661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK3Oa43lmLem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UkV66dgmlyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1, f2, f3 = prediction.T"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylg5f6AXmkhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f8d1d0a5-ec4d-4ba2-f6b8-56f95d65bf23"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes(projection = '3d')\n",
        "ax.plot3D(f1, f2, f3, 'o')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<mpl_toolkits.mplot3d.art3d.Line3D at 0x7fdaa468da58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZKPk2l1krmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqPagbGMkovO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "2997cb7c-b2d7-4d6f-fbe5-a30f75122139"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "    # open a GradientTape to record the operations run during the feed forward\n",
        "    # enables aoto-partial-Differentiation\n",
        "    with tf.GradientTape() as tape:\n",
        "      # run the feed foward process of the layers.\n",
        "      # the operations that the layers apply to its inpurts and going to bee recorded on the GradientTape\n",
        "      linear = model(x_batch_train, training = True)\n",
        "      # print(linear)\n",
        "      # compute the loss value for this minibatch\n",
        "      # mse = Keras_loss_function(y_batch_train, linear)\n",
        "      mse = tf.keras.losses.MSE(y_batch_train, linear)\n",
        "      \n",
        "      # print(mse)\n",
        "      # mse = keras.losses.mean_squared_error(y_batch_train, linear) # mse gives 3 number\n",
        "    # print(mse)\n",
        "    # use the gradient tap to automatically retrieve the gradients of the \n",
        "    # trainable variables with respect to the loss\n",
        "    grads = tape.gradient(mse, model.trainable_weights)\n",
        "    # print(grads)\n",
        "    # weight + bias for every layer\n",
        "    # run one step of gradient dscent by updating the value of the variables to minize the loss\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    # print(model.trainable_weights,'\\n')\n",
        "    # print log information every 10 batches.\n",
        "    if step % 10 == 0:\n",
        "      print(\n",
        "          \"Training loss (for one batch) at step %d: %.4f\"\n",
        "          %(step, float(mse))\n",
        "      )\n",
        "      print(\"seen so far: %s samples\" % ((step +1) * 100))\n",
        "\n",
        "\n",
        "  # Run a validation loop at the end of each epoch\n",
        "  for x_batch_val, y_batch_val in val_dataset:\n",
        "    val_linear = model(x_batch_val, training = False)\n",
        "    val_mse = Keras_loss_function(y_batch_val, val_linear)\n",
        "\n",
        "  # print MSE for validation set\n",
        "  print(\"validation MSE: %.4f\" % (float(val_mse)))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "tf.Tensor(\n",
            "[0.57494587 0.33508238 0.35065326 0.35559705 0.32295063 0.3999525\n",
            " 0.5411604  0.3343054  0.34423485 0.30070588 0.44833454 0.59872377\n",
            " 0.28540817 0.29142806 0.3642987  0.41084838 0.56092745 0.30895713\n",
            " 0.35482576 0.24976857 0.1670237  0.2851925  0.23831482 0.22105622\n",
            " 0.1412197  0.24243145 0.5348261  0.4946928  0.34075102 0.40731737\n",
            " 0.79314345 0.4384757  0.524164   0.6165649  0.32332203 0.5213592\n",
            " 0.5354426  0.40206334 0.63454676 0.9144104  0.6955177  0.4079878\n",
            " 0.297591   0.57673997 0.30996206 0.25372437 0.24239714 0.2499665\n",
            " 0.54856634 0.33951893 0.38865852 0.3212984  0.27440608 0.6210764\n",
            " 0.25334936 0.33233312 0.19609107 0.4277029  0.55745345 0.21814251\n",
            " 0.5449433  0.5946722  0.6395524  0.2264504  0.88247204 0.3592948\n",
            " 0.29292303 0.35146663 0.2740141  0.5927867  0.27163103 0.2581769\n",
            " 0.7544055  0.21777324 0.57660854 0.28524604 0.3367664  0.30108866\n",
            " 0.5702116  0.33767867 0.30924603 0.32740083 0.45310566 0.50131106\n",
            " 0.27663317 0.5209438  0.37912664 0.7450841  0.45897296 0.37904158\n",
            " 1.1129282  0.3439413  0.23940015 0.40174267 0.28176156 0.2405665\n",
            " 0.39068535 0.28281257 0.68446714 0.33697045], shape=(100,), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b1d4698fd1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m       print(\n\u001b[1;32m     31\u001b[0m           \u001b[0;34m\"Training loss (for one batch) at step %d: %.4f\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       )\n\u001b[1;32m     34\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seen so far: %s samples\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    }
  ]
}